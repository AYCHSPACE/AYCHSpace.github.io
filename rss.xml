<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>plan ➔ space</title>
    <link>http://planspace.org/</link>
    <description>plan space from outer nine</description>
    <language>en-us</language>
    <atom:link href="http://planspace.org/rss.xml" rel="self" type="application/rss+xml" />
<item>
<title>R Squared Can Be Negative</title>
<description><![CDATA[

<p>Let's do a little linear regression in Python with <a href="http://scikit-learn.org/">scikit-learn</a>:</p>
<pre><code class="language-python">import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.cross_validation import train_test_split

X, y = np.random.randn(100, 20), np.random.randn(100)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)</code></pre>

<p>It is a property of <a href="http://en.wikipedia.org/wiki/Ordinary_least_squares">ordinary least squares regression</a> that for the training data we fit on, the <a href="http://en.wikipedia.org/wiki/Coefficient_of_determination">coefficient of determination R<sup>2</sup></a> and the square of the <a href="http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient">correlation coefficient r<sup>2</sup></a> of the model's predictions with the actual data are equal.</p>
<pre><code class="language-python"># coefficient of determination R^2
print model.score(X_train, y_train)
## 0.203942898079

# squared correlation coefficient r^2
print np.corrcoef(model.predict(X_train), y_train)[0, 1]**2
## 0.203942898079</code></pre>

<p>This does not hold for new data, and if our model is sufficiently bad the coefficient of determination can be negative. The squared correlation coefficient is never negative but can be quite low.</p>
<pre><code class="language-python"># coefficient of determination R^2
print model.score(X_test,  y_test)
## -0.277742673311

# squared correlation coefficient r^2
print np.corrcoef(model.predict(X_test), y_test)[0, 1]**2
## 0.0266856746214</code></pre>

<p>This worsening will always happen to some extent, and worsen with <a href="http://en.wikipedia.org/wiki/Overfitting">overfitting</a>.</p>    
    ]]></description>
<link>http://planspace.org/20150417-negative_r_squared/</link>
<guid>http://planspace.org/20150417-negative_r_squared/</guid>
<pubDate>Fri, 17 Apr 2015 12:00:00 -0500</pubDate>
</item>
<item>
<title>RStudio in a Web Browser</title>
<description><![CDATA[

<p>The most annoying part of <code>R</code> workshops is installing software and downloading necessary files. With RStudio Server, workshop participants can skip all that entirely.</p>
<p>Here's what RStudio looks like running locally. To attain the setup shown, you need to install <a href="http://www.r-project.org/">R</a>, install <a href="http://www.rstudio.com/">RStudio</a>, install necessary R <a href="http://cran.r-project.org/">packages</a>, separately download necessary code and data, and navigate to the correct working directory.</p>
<p><img alt="RStudio running locally" src="local.png"></p>
<p>Here's what RStudio looks like in a browser. To attain the setup shown, you go to a URL and log in.</p>
<p><img alt="RStudio in a browser" src="web.png"></p>
<p>In a workshop, it's very nice to be able to start doing things with <code>R</code> without messing with setup. Somebody does have to set up the environment in advance though.</p>
<p>Setting up RStudio Server is very easy, especially if you're already familiar with Amazon Web Services (<a href="http://aws.amazon.com/">AWS</a>):</p>
<ul>
<li>Spin up an AWS Elastic Compute Cloud (<a href="http://aws.amazon.com/ec2/">EC2</a>) machine using <a href="http://www.louisaslett.com/RStudio_AMI/">Louis Aslett's RStudio Amazon Machine Image (AMI)</a>.<ul>
<li><a href="http://www.louisaslett.com/RStudio_AMI/">Louis's page</a> has good concise directions on how to do this&#8212;follow his directions!</li>
</ul>
</li>
<li>Secure Shell (SSH) into your EC2 machine and set up the environment as you want it to be.<ul>
<li>Install globally required packages while running R as root (<code>sudo R</code>).</li>
<li>Put necessary files (code, data, etc.) as desired in <code>/home/rstudio</code> (the prototypical user).</li>
<li>Run <a href="https://gist.github.com/ajschumacher/12f7484d06cacd4b4cd3">build_logins.sh</a>, a script developed by <a href="https://twitter.com/joshdata">Josh Tauberer</a>, to create the desired number of user accounts. (See documentation in the script itself.)</li>
</ul>
</li>
<li>You can optionally give your EC2 machine an AWS <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html">elastic IP address</a>, which will let you start and stop the machine (avoiding the cost of keeping it running when you aren't using it) but still know in advance what address the machine will be accessible at.<ul>
<li>Be sure your EC2 machine and elastic IP are both &#8220;EC2 classic&#8221; or both Virtual Private Cloud (VPC). (Some instance types are only available in VPC!)</li>
</ul>
</li>
</ul>
<p>For an in-person workshop, it can be effective to distribute login information on slips of paper like this:</p>
<p><img alt="workshop login information" src="paper.png"></p>
<p>I've led an <a href="/20150220-data_science_isnt_magic/">introductory workshop</a> with ten active participants on one EC2 m3.2xlarge, which runs at 56 cents per hour. For a larger group, I ran two m3.2xlarge machines and three c4.8xlarge machines ($1.856/hour). That used all my five elastic IP addresses and provided 124 vCPUs and 240 gigs of RAM. We had 94 active users and could probably have supported quite a few more without problems.</p>
<p>RStudio in the cloud is a great fit for workshops because it eliminates install and setup pain for participants. It lets you decouple the install process from other workshop activities. The experience of using RStudio in a browser is nice enough that it makes me wonder whether anyone offers cloud RStudio as a service&#8212;is that a business that should exist? Workshops certainly aren't the only place where RStudio Server could make sense.</p>
<p>There are also other options for setting up your server. You don't need to use Louis's AMIs; you don't need to use AWS at all. The <a href="http://www.bioconductor.org/">Bioconductor Project</a> maintains a <a href="http://www.bioconductor.org/help/bioconductor-cloud-ami/">Cloud AMI</a> that comes with a lot of other pre-installed R packages, for example. (When I last checked it was based on an older version of Ubuntu.) For total control, you can install <a href="http://www.rstudio.com/products/rstudio/download-server/">RStudio Server</a> from scratch on whatever type of system you like.</p>    
    ]]></description>
<link>http://planspace.org/20150221-rstudio_in_a_web_browser/</link>
<guid>http://planspace.org/20150221-rstudio_in_a_web_browser/</guid>
<pubDate>Sat, 21 Feb 2015 12:00:00 -0500</pubDate>
</item>
<item>
<title>Data Science isn't Magic</title>
<description><![CDATA[

<p>This is the flow for a <a href="http://dc.opendataday.org/">DC Open Data Day</a> 2015 workshop. It may not make sense out of context. For a fun summary in tweets (with photos!) you might check out <a href="https://storify.com/planarrowspace/data-science-isn-t-magic-workshop-at-dc-open-data">a storification of it</a>.</p>
<p>View this page as <a href="big.html">slides</a> to make this site's base URL appear quite large so that people can find this easily.</p>
<hr>
<p>planspace.org</p>
<hr>
<h3>Workshop Outline</h3>
<ul>
<li>Intro / Disclaimer</li>
<li><a href="80_percent_definitions/">80% Definitions</a> (<a href="80_percent_definitions/big.html">slides</a>)</li>
<li><a href="osemn/">Data Science is OSEMN</a> (<a href="osemn/big.html">slides</a>)</li>
<li><a href="problem/">What's the Problem?</a> (<a href="problem/big.html">slides</a>)</li>
<li>Find NYC attendance data<ul>
<li><a href="http://schools.nyc.gov/">schools.nyc.gov</a></li>
<li><a href="http://schools.nyc.gov/AboutUs/">About Us</a></li>
<li><a href="http://schools.nyc.gov/AboutUs/schools/">Our Schools</a></li>
<li><a href="http://schools.nyc.gov/AboutUs/schools/data/">Data About Schools</a></li>
<li><a href="http://schools.nyc.gov/AboutUs/schools/data/Attendance.htm">Daily Attendance Rates</a></li>
<li><a href="http://schools.nyc.gov/aboutus/data/attendancexml/">XML</a></li>
<li><a href="http://schools.nyc.gov/AboutUs/schools/data/attendancexml/">http://schools.nyc.gov/AboutUs/schools/data/attendancexml/</a></li>
</ul>
</li>
<li>Data Science <a href="tools/">Tools</a> (<a href="tools/big.html">slides</a>)</li>
<li>Connect to RStudio in the cloud<ul>
<li>Backup plan:<ul>
<li>Install the appropriate <code>R</code> distribution for your system from this <a href="http://watson.nci.nih.gov/cran_mirror/">mirror</a>.</li>
<li>Install the <a href="http://www.rstudio.com/ide/download/desktop">RStudio IDE</a> for <code>R</code>. The RStudio site should suggest an appropriate package for your system.</li>
<li>Download and unzip the <a href="https://github.com/ajschumacher/odddsim/archive/master.zip">files</a> we're using. (They're <a href="https://github.com/ajschumacher/odddsim">on GitHub</a>, so you can clone if you prefer.)</li>
</ul>
</li>
</ul>
</li>
<li>Working with <code>R</code><ul>
<li>Working with one day of data (<code>01-day_attendance.R</code>)</li>
<li>Selecting usable data points (<code>02-select_totals.R</code>)</li>
<li>The relationship between temperature and attendance (<code>03-merge_and_plot.R</code>)</li>
</ul>
</li>
<li>Bonus: Introducing the DC voter file</li>
</ul>
<h3>Additional Resources</h3>
<ul>
<li>For learning <code>R</code>:<ul>
<li><a href="http://tryr.codeschool.com/">Try R</a> is an interactive web site that guides you through <code>R</code> functionality in your web browser.</li>
<li>The <a href="https://raw.githubusercontent.com/ajschumacher/gadsdc/master/02-R/walking_intro.Rmd">walking introduction to R</a> is an <code>R</code> script that you can open and work through in RStudio.</li>
</ul>
</li>
<li>For more fun data:<ul>
<li><a href="http://blogs.worldbank.org/opendata/accessing-world-bank-data-apis-python-r-ruby-stata">Accessing the World Bank Data APIs in Python, R, Ruby &amp; Stata</a></li>
<li>The <a href="https://github.com/ajschumacher/dc_voter_reg">DC voter registration file</a></li>
</ul>
</li>
</ul>    
    ]]></description>
<link>http://planspace.org/20150220-data_science_isnt_magic/</link>
<guid>http://planspace.org/20150220-data_science_isnt_magic/</guid>
<pubDate>Fri, 20 Feb 2015 12:00:00 -0500</pubDate>
</item>
<item>
<title>To Migrate from GitHub to BitBucket</title>
<description><![CDATA[

<p><a href="https://github.com/">GitHub</a> has great design and unlimited collaborators but no free private repos. <a href="https://bitbucket.org/">BitBucket</a> has unlimited free private repos but a limit of five collaborators on them. Assuming you want your repos private so that very few people have access to them, BitBucket is perfect.</p>
<p>BitBucket makes migrating from GitHub ridiculously easy. They have a <a href="https://blog.bitbucket.org/2013/04/02/finnovation-brings-you-a-heap-of-new-features/">one-click integration</a> and everything. But it's harder to migrate issues.</p>
<p>Joe Workman <a href="http://joeworkman.tumblr.com/post/40133335482/migrating-from-github-to-bitbucket">made</a> <a href="http://www.bytebucket.org/joeworkman/git2bit">git2bit</a>, which magically puts issues from a GitHub repository into a BitBucket repository. The systems aren't exactly the same, but it makes mostly intelligent choices for how to convert.</p>
<p>You already have Ruby installed, so it should be this easy to install <code>git2bit</code>:</p>
<pre><code class="language-bash">gem install git2bit</code></pre>

<p>Alas, <code>git2bit</code> depends on both <a href="https://rubygems.org/gems/bitbucket_rest_api">bitbucket_rest_api</a> and <a href="https://rubygems.org/gems/github_api">github_api</a>, taking their most recent versions by default, and these two gems now require conflicting versions of <a href="https://rubygems.org/gems/hashie">hashie</a>.</p>
<p>This is what I did:</p>
<pre><code class="language-bash">gem install hashie -v 2.0.5
gem install github_api -v 0.11.3
gem install bitbucket_rest_api -v 0.1.5
gem install git2bit -v 1.0.2</code></pre>

<p>At last! Use <code>git2bit --help</code> to see the fairly clear options.</p>
<p>It seems the default is to migrate only open issues, but if you use the <code>--closed</code> flag it will migrate both open and closed issues, which is what I wanted. Be aware that there's no checking for duplication, so if you run <code>git2bit</code> twice you will get double the issues on the BitBucket side. It's easy to make an empty repo to test that things are working as intended.</p>
<p>Other minutiae:</p>
<p>If you want to have a different identity for some repos (the ones on BitBucket, say) this is easy to set on a per-repo basis. These commands will alter a repo's <code>.git/config</code>:</p>
<pre><code class="language-bash">git config user.name "Your Name Here"
git config user.email your@email.com</code></pre>

<p>On BitBucket you'll want to <a href="https://confluence.atlassian.com/display/BITBUCKET/Add+an+SSH+key+to+an+account">Add an SSH key to an account</a> and <a href="https://confluence.atlassian.com/display/BITBUCKET/Use+the+SSH+protocol+with+Bitbucket">Use the SSH protocol with Bitbucket</a>.</p>
<p>To point a current local repo up to BitBucket:</p>
<pre><code class="language-bash">git remote remove origin
git remote add origin git@bitbucket.org:accountname/reponame.git</code></pre>

<p>And if you didn't use the one-click migration but are instead doing your initial push to BitBucket from your local repo:</p>
<pre><code class="language-bash">git push -u origin --all
git push -u origin --tags</code></pre>

<p>That's just copied from BitBucket's directions when you create a new repo, which I like for being more complete than GitHub's.</p>    
    ]]></description>
<link>http://planspace.org/20150126-to_migrate_from_github_to_bitbucket/</link>
<guid>http://planspace.org/20150126-to_migrate_from_github_to_bitbucket/</guid>
<pubDate>Mon, 26 Jan 2015 12:00:00 -0500</pubDate>
</item>
<item>
<title>Monads by Diagram</title>
<description><![CDATA[

<p>Let's get some notation out of the way:</p>
<p><img alt="intput -&gt; function -&gt; output" src="function_notation.jpg"></p>
<p>A &#8220;function&#8221; is represented by a rectangle. Its arguments (&#8220;input&#8221;) appear above it, and its result (&#8220;output&#8221;) appears to its right.</p>
<p><img alt="value and monadic value" src="values.jpg"></p>
<p>We have some idea of &#8220;values&#8221; which can be worked with. We introduce the idea of a &#8220;monadic value&#8221; which can be thought of as &#8220;wrapping&#8221; our more familiar values.</p>
<p><img alt="unit" src="unit.jpg"></p>
<p>There's a function called &#8220;unit&#8221; which takes a value and returns a monadic value. Now we can make monadic values from our usual values.</p>
<p><img alt="bind" src="bind.jpg"></p>
<p>There's a function called &#8220;bind&#8221; which takes a function and a monadic value. The argument function takes a value and returns a monadic value. The argument monadic value gets unwrapped by &#8220;bind&#8221; and its value becomes the argument to the passed function. Now we can do things to our monadic values.</p>
<p>That's it. Monads are defined. They should obey some reasonable rules, but that&#8217;s it.</p>
<p><em>And yet you want more?</em></p>
<p><img alt="map" src="map.jpg"></p>
<p>Nobody wants to write functions that take a normal value and return a monadic value. The &#8220;map&#8221; function takes a normal function that knows nothing about monads and returns a function that takes and returns monadic values. Just use the resulting function on your monadic values! So convenient!</p>
<p><img alt="join" src="join.jpg"></p>
<p>The &#8220;join&#8221; function unwraps a doubly-monadic value. You want this.</p>
<p><img alt="bind via map and join" src="bind_via_map_and_join.jpg"></p>
<p>We can combine the &#8220;map&#8221; and &#8220;join&#8221; functions to get the &#8220;bind&#8221; function. Pretty neat!</p>
<p><em>And yet you want a real explanation?</em></p>
<p>For a lucid formal exposition, read <a href="http://homepages.inf.ed.ac.uk/wadler/papers/marktoberdorf/baastad.pdf">Monads for Functional Programming</a>. The above is my attempt to express the key definitions there, without the mathematical Haskell notation.</p>
<p>For a plain-talking explanation with practical examples in friendly Ruby, <a href="http://codon.com/refactoring-ruby-with-monads">read</a> or (preferably) <a href="https://www.youtube.com/watch?v=uTR__8RvgvM">watch</a> Refactoring Ruby with Monads. <a href="https://twitter.com/tomstuart">Tom Stuart</a> uses <code>from_value</code> for &#8220;unit&#8221;, <code>and_then</code> for &#8220;bind&#8221;, and <code>within</code> for calling &#8220;map&#8221; and applying the result.</p>
<p>For a great overview of even more kinds of things and much better illustration than I can manage, read <a href="http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html">Functors, Applicatives, And Monads In Pictures</a>. This follows the Haskell in using <code>fmap</code> for &#8220;map&#8221;.</p>
<p>And <a href="http://james-iry.blogspot.com/2009/05/brief-incomplete-and-mostly-wrong.html">don't forget</a>:</p>
<blockquote>
<p>&#8220;a monad is a monoid in the category of endofunctors, what's the problem?&#8221;</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20150125-monads_by_diagram/</link>
<guid>http://planspace.org/20150125-monads_by_diagram/</guid>
<pubDate>Sun, 25 Jan 2015 12:00:00 -0500</pubDate>
</item>
<item>
<title>Use pew, not virtualenvwrapper, for Python virtualenvs</title>
<description><![CDATA[

<p>Have you noticed how good <a href="http://docs.python-guide.org/">The Hitchhiker&#8217;s Guide to Python</a> is? The documentation there on <a href="http://docs.python-guide.org/en/latest/dev/virtualenvs/">virtualenv</a> is exemplary.</p>
<p>Of course nobody wants to use virtualenvs directly, which is why virtualenvwrapper exists. But as <a href="http://datagrok.org/">Lamb</a> pointed out, <a href="https://gist.github.com/datagrok/2199506">Virtualenv's <code>bin/activate</code> is Doing It Wrong</a>, and virtualenvwrapper doesn't do it right either. Also, it's annoying to run env'ed Python via <a href="http://en.wikipedia.org/wiki/Cron">cron</a>.</p>
<p>The solution is to use <a href="https://github.com/berdario/pew">pew</a> instead. The Python Environment Wrapper (pew) handles your environment elegantly. This includes not mangling your <code>PS1</code>, though you can still display <code>VIRTUAL_ENV</code> information in your prompt if you want, and however you want. Also, suddenly all your virtualenv tasks are pew sub-commands, which means all you have to remember is <code>pew</code>. Typing <code>pew</code> alone shows all the pew commands, with helpful descriptions.</p>
<p>I no longer set the <code>WORKON_HOME</code> environment variable. This means pew will use the default <code>~/.local/share/virtualenvs</code>, which is a good choice. It's consistent with <a href="https://www.python.org/dev/peps/pep-0370/">PEP 370</a>, and it means you don't rely on <code>WORKON_HOME</code> to find your virtualenvs, which is nice for cron.</p>
<p>The location of <code>pew</code> is <code>/usr/local/bin</code>. For convenience, I suggest adding a <code>PATH</code> line to your crontab. The default <code>PATH</code> is <code>/usr/bin:/bin</code>, so the following adds one entry:</p>
<pre><code>PATH=/usr/local/bin:/usr/bin:/bin</code></pre>

<p>With that done, you can easily run any Python script you want in any virtualenv you want, via cron, with concise syntax:</p>
<pre><code>* * * * * pew in my_env my_script.py</code></pre>

<p>The example assumes <code>my_script.py</code> is in your home directory, executable, and with the standard <code>#!/usr/bin/env python</code> shebang.</p>
<p>I find this to be a very nice setup: <code>pew workon my_env</code> and develop <code>my_script.py</code> however I want, and <code>pew in my_env my_script.py</code> to run in that virtualenv from cron or anywhere else.</p>
<hr>
<p>Related tools: <a href="https://virtualenv.pypa.io/">virtualenv</a>, <a href="https://virtualenvwrapper.readthedocs.org/">virtualenvwrapper</a>, <a href="https://github.com/sashahart/vex">vex</a>, <a href="https://github.com/zimbatm/direnv">direnv</a>, probably more...</p>
<p>Thanks to <a href="https://twitter.com/jessicagarson">Jessica</a>, <a href="https://twitter.com/necaris">Rami</a>, and <a href="https://twitter.com/reconbot">Francis</a> for thoughts on this.</p>    
    ]]></description>
<link>http://planspace.org/20150120-use_pew_not_virtualenvwrapper_for_python_virtualenvs/</link>
<guid>http://planspace.org/20150120-use_pew_not_virtualenvwrapper_for_python_virtualenvs/</guid>
<pubDate>Tue, 20 Jan 2015 12:00:00 -0500</pubDate>
</item>
<item>
<title>gog: a separate layer for visualization</title>
<description><![CDATA[

<p><em>A short presentation at the DC <a href="http://www.meetup.com/TrackMaven-Monthly-Challenge/">Monthly Challenge</a> on <a href="http://www.meetup.com/TrackMaven-Monthly-Challenge/events/219314544/">Monday January 19, 2015</a>.</em></p>
<hr>
<p><img alt="gog" src="gog.png"></p>
<hr>
<p><code>gog</code> is a name for a simple idea I've been exploring about making it easy to quickly see data from whatever computing environment you happen to be in.</p>
<p>First I'll talk about <em>quickly</em>, then I'll talk about <em>from whatever</em>, and then I'll show some <code>gog</code> prototype work.</p>
<p>There are two kinds of <em>quickly</em> that I care about. One is getting images produced quickly, and another is working with or exploring them quickly.</p>
<hr>
<pre><code class="language-r">plot(data)</code></pre>

<hr>
<p>This is <code>R</code>. <code>R</code> can produce plots quickly. The <code>plot</code> function is generic and will dispatch to a method that knows how to plot whatever you're plotting. This is very nice for the user.</p>
<hr>
<p><img alt="one-dimensional R plot" src="plot_r_1.png"></p>
<hr>
<p>If you plot a single vector, you get an image like this with the index in the horizontal direction.</p>
<hr>
<p><img alt="two-dimensional R plot" src="plot_r_2.png"></p>
<hr>
<p>If you plot a data frame with two fields, you get a familiar scatterplot.</p>
<hr>
<p><img alt="three-dimensional R plot" src="plot_r_3.png"></p>
<hr>
<p>If you plot a data frame with more than two fields, you get a scatterplot matrix.</p>
<hr>
<p><img alt="linear model diagnostic R plots" src="plot_r_4.png"></p>
<hr>
<p>And if you plot a linear model object, you get four diagnostic plots.</p>
<p>All of these plots were created with <code>plot(data)</code>. There are a lot of defaults chosen in order to get something on the screen. You might also want to see another view, but the pure convenience of being able to <code>plot(data)</code> so easily is really wonderful.</p>
<p>The only way to reduce the friction of graphing even further would be to have plots automatically generated in the background based on whatever data you have on your system. I <a href="https://twitter.com/planarrowspace/status/555893329460994048">think</a> that would be a fun project, in fact.</p>
<p>Once you have an image, you want to be able to work with it quickly and easily. This means interaction with the image itself, and this is a place that <code>R</code> is not particularly strong, at least with base graphics.</p>
<hr>
<p><img alt="paper plot" src="paper_plot.png"></p>
<hr>
<p>A lot of statistical graphics behave essentially like paper. I like paper a lot, but computers can do more. We should expect, at a minimum, to be able to point to a data element and find out more about it. There are tons of other direct manipulation ways to interact with graphics (like brushing) that we should be able to have easily at our disposal.</p>
<p>Most of the world agrees that the way to get interactivity is to use web frontend things, and I'm inclined to think so too. It does often seem that the time to produce a visualization has a dramatic inverse relationship with the amount of interactivity supported, however.</p>
<p>In summary:</p>
<ul>
<li>Interactivity lets us quickly work with plots.</li>
<li>A simple user API lets us quickly make plots.</li>
</ul>
<p>What about <em>from whatever</em>?</p>
<hr>
<p><img alt="diagram of R graphics ecosystem" src="graphics_r.png"></p>
<hr>
<p><code>R</code> can make a lot of different graphics. Parts of the ecosystem are organized in clever ways that make things convenient for <code>R</code> users, and there's just a ton available. It seems fine to make our graphics in <code>R</code>. But what about other languages?</p>
<hr>
<p><img alt="diagram of R, Python, and Julia graphics ecosystem" src="graphics_multi.png"></p>
<hr>
<p>The current status quo is mostly to not share graphics capabilities between languages. So if Python want to have <code>ggplot</code>, <a href="https://yhathq.com/">somebody</a> has to <a href="http://ggplot.yhathq.com/">port</a> it over, which takes a bunch of work. And newer languages can be at a disadvantage purely because they don't have as much tooling for visualization, despite other strengths.</p>
<p>What I'm suggesting is that we might be able to pull the graphics parts out of our data languages.</p>
<hr>
<p><img alt="diagram of gog graphics ecosystem" src="graphics_gog.png"></p>
<hr>
<p>So this is the idea. You make the control surface inside various languages quite small and easy, so that everybody can connect into a sort of shared library of visualization pieces.</p>
<hr>
<p><img alt="cover of The Grammar of Graphics" src="gg_cover.jpg"></p>
<hr>
<p>As an aside:</p>
<p>The grammar of graphics seems to be a good idea, and the <a href="http://www.amazon.com/The-Grammar-Graphics-Statistics-Computing/dp/0387245448">book</a> is also quite good. A lot of what's good about Tableau is good because of the grammar of graphics.</p>
<p>However, the design that should be influenced by the grammar of graphics is not the part that <code>gog</code> is directly concerned with.</p>
<hr>
<pre><code class="language-r">ggplot(data) +
  aes(x=thing) +
  geom_histogram() +
  # etc.</code></pre>

<hr>
<p>To make a comparison to R's <code>ggplot2</code>, notice that you always start by passing data in. Then <code>ggplot2</code> let's you specify everything about your plot&#8212;and you <em>have</em> to specify a good deal before you get any plot at all.</p>
<hr>
<pre><code class="language-r">gog(data)
# etc. happens elsewhere</code></pre>

<hr>
<p>What <code>gog</code> suggests is to standardize the data passing, but then the way that the plot gets made is none of <code>gog</code>'s business. It's probably a good idea to start with some default plot and then let users work with it further.</p>
<p>So what is all this nonsense, and how could it work?</p>
<hr>
<p><img alt="gogd console" src="gogd.png"></p>
<hr>
<p>The connecting component is a <code>gog</code> HTTP server which runs on port 4808 and just accepts POST requests at <code>/data</code> and rebroadcasts it to anything listening to a websocket also at <code>/data</code>. The assumption is that we're passing a JSON array of objects.</p>
<p>I have <a href="https://github.com/ajschumacher/gogd">a gog server</a> written in Clojure, but a server can be implemented and hosted however you want, as long as everything connects.</p>
<hr>
<p><img alt="charted.co welcome screen" src="charted.png"></p>
<hr>
<p>People have already made some visualizations that are suitable for adapting to use with <code>gog</code>. As an example, I took the code from <a href="http://www.charted.co/">charted.co</a>, which was designed to load data from CSV files, and adapted it to also allow input from <code>gog</code>.</p>
<hr>
<pre><code class="language-python"># pip install gogpy
from gogpy import gog
import numpy as np
import pandas as pd
gog(pd.DataFrame(np.random.sample(10)))</code></pre>

<hr>
<p>The <code>gogpy</code> package is ridiculously small, but can still be <code>pip</code> installed from <a href="https://pypi.python.org/pypi">PyPI</a> for your convenience. Currently the <code>gog</code> function will only take a <code>pandas</code> <code>DataFrame</code>.</p>
<hr>
<p><img alt="charted.co graph" src="charted_demo.png"></p>
<hr>
<p>Thanks to the work that went into making <code>charted.co</code>, we have a graph already.</p>
<hr>
<pre><code class="language-python">import time
data = pd.DataFrame(np.random.sample(100))
for i in range(91):
    gog(data[i:i+10])
    time.sleep(2)</code></pre>

<hr>
<p>Live updates are the only thing happening&#8212;it just depends on when you send the data.</p>
<hr>
<pre><code class="language-r"># install_github("ajschumacher/gogr")
library("gogr")
data &lt;- data.frame(0-runif(100))
for (i in 1:91) {
    gog(data[i:(i+9), ,drop=F])
    Sys.sleep(2)
}</code></pre>

<hr>
<p>The <code>R</code> package <a href="https://github.com/ajschumacher/gogr">gogr</a> isn't on <a href="http://cran.r-project.org/">CRAN</a> but can be installed with <a href="https://github.com/hadley/devtools">devtools</a>. It's trivially easy to use any visualization that supports <code>gog</code> from any environment that supports <code>gog</code>.</p>
<hr>
<pre><code class="language-r">rstudio::viewer("http://localhost:8000")
library("gogr")
data &lt;- iris
names(data)[1:2] &lt;- c("x", "y")
gog(data)</code></pre>

<hr>
<p>It turns out that the <a href="http://www.rstudio.com/">RStudio</a> viewer pane is really just <a href="https://www.webkit.org/">WebKit</a> and it's easy to plug in <code>gog</code> visualizations.</p>
<hr>
<p><img alt="visualizing iris sepal length vs. sepal width" src="gogi_iris.png"></p>
<hr>
<p>I made this little visualization, a simple scatterplot with <a href="http://d3js.org/">D3</a>. It's very crude at the moment, but it's enough to show sepal length versus sepal width, and to show information about data points as we explore around. This could obviously be much improved with such luxuries as axes, and replace the renaming of columns to &#8217;x&#8217; and &#8217;y&#8217; with defaulting and interaction. And using &#8220;title&#8221; elements for tooltips has only the advantage of expediency.</p>
<p>But even in its current state this visualization allows for fun data manipulation experiments with animated updates which would be much more work to achieve with other techniques. (See <a href="demo.R">demo.R</a> for the complete <code>R</code> demo source.)</p>
<hr>
<pre><code class="language-python"># access meetup API and extract data, then:
data = pd.DataFrame({'x': rsvped, 'y': ids, 'name': names})
gog(data)</code></pre>

<hr>
<p>Of course nobody cares about irises - let's pull some data about humans we know, using the Meetup API. (See <a href="demo.py">demo.py</a> for complete Python demo source.)</p>
<hr>
<p><img alt="visualizing RSVP time vs. member ID" src="gogi_meetup.png"></p>
<hr>
<p>Even though we collected data with Python, we can visualize it wherever we want, including back inside the RStudio interface.</p>
<p>I haven't tried it, but it strikes me that it would be pretty straightforward to cobble together an RStudio-style Python IDE, at least with a REPL and <code>gog</code> visualization container, using existing components.</p>
<hr>
<p>Thank you!</p>
<hr>
<p>This is all very preliminary and there are no doubt a lot of complications and other things to consider. The question of how to manage possibly many <code>gog</code> visualization frontends or have any sort of dispatch system is not at all addressed, for instance. And there are a number of more or less related projects, which I've started to collect at <a href="https://github.com/ajschumacher/gog">ajschumacher/gog</a>. Any and all feedback, suggestions, or anything else appreciated!</p>    
    ]]></description>
<link>http://planspace.org/20150119-gog_a_separate_layer_for_visualization/</link>
<guid>http://planspace.org/20150119-gog_a_separate_layer_for_visualization/</guid>
<pubDate>Mon, 19 Jan 2015 12:00:00 -0500</pubDate>
</item>
<item>
<title>A Great Python Book explains Hash Tables</title>
<description><![CDATA[

<p><a href="http://mitpress.mit.edu/books/introduction-computation-and-programming-using-python-0">Introduction to Computation and Programming Using Python</a> is the book you should get if you think you want to learn Python. It packs in tons of sophisticated content and makes it accessible, not dumbed down.</p>
<p><a href="http://mitpress.mit.edu/books/introduction-computation-and-programming-using-python-0"><img alt="Introduction to Computation and Programming Using Python" src="cover.jpg"></a></p>
<p>This book seems to be something of a hidden gem. It isn't what comes up first when you search for Python resources. It doesn't have a lot of flash or promotion behind it. Of course it does have the weight of its publisher, The MIT Press. And there's the blurb on the back cover from Hal Abelson, coauthor of <a href="https://mitpress.mit.edu/sicp/">Structure and Interpretation of Computer Programs</a>. So there are clear signs of the book's quality.</p>
<p>One example of what's good about this book is the explanation of <em>hashing</em>. This is a very important topic, but it has a little bit of complexity to it and so it's often almost entirely omitted when teaching people to code. This is the depth sometimes given in introductory Python courses:</p>
<pre><code class="language-python"># A Python dictionary is a set of key-value pairs
my_dict = {'a_key': 'a_value', 'another_key': 'another_value'}
# which allows access to the values via the keys (lookup)
my_dict['another_key']  # 'another_value'
# This data structure is also known as a `map` or `hash-map`</code></pre>

<p>That's true, and you can start to use the language functionality with that, but it doesn't help you understand the underlying key idea. Below is part of the treatment from <em>Introduction to Computation and Programming Using Python</em>, in section 10.3 <em>Hash Tables</em>:</p>
<section style="font-family: sans-serif">

<p>... [Python] dictionaries use a technique called hashing to do the lookup in time that is nearly independent of the size of the dictionary. The basic idea behind a <strong>hash table</strong> is simple. We convert the key to an integer, and then use that integer to index into a list, which can be done in constant time. In principle, values of any immutable type can be easily converted to an integer. After all, we know that the internal representation of each object is a sequence of bits, and any sequence of bits can be viewed as representing an integer.  For example, the internal representation of <code>'abc'</code> is the string of bits 011000010110001001100011, which can be viewed as a representation of the decimal integer 6,382,179. Of course, if we want to use the internal represntation of strings as indices into a list, the list is going to have to be pretty darn long.</p>

<p>What about situation swhere the keys are already integers? Imagine, for the moment, that we are implementing a dictionary all of whose keys are U.S. Social Security numbers. (A United States Social Security number is a nine-digit integer.) If we represented the dictionary by a list with 10<sup>9</sup> elements and used Social Security numbers to index into the list, we could do lookups in constant time. Of course, if the dictionary contained entires for only ten thousand (10<sup>4</sup>) people, this would waste quite a lot of space.</p>

<p>Which gets us to the subject of hash functions. A <strong>hash function</strong> maps a large space of inputs (e.g., all natural numbers) to a smaller space of outputs (e.g., the natural numbers between 0 and 5000). Hash functions can be used to convert a large space of keys to a smaller space of integer indices.</p>

<p>Since the space of possible outputs is smaller than she space of possible inputs, a shash function is a <strong>many-to-one mapping</strong>, i.e., multiple different inputs may be mapped to the same output. When two inputs are mapped to the same output, it is called a <strong>collision</strong>&#8212;a topic which we will return to shortly. A good hash function produces a <strong>uniform distribution</strong>, i.e., every output in the range is equally probable, which minimizes the probability of collisions.</p>

<p>Designing good hash functions is surprisingly challenging. The problem is that one wants the outputs to be uniformly distributed given the expected distribution of inputs. Suppose, for example, that one hashed surnames by performing some calculation on the first three letters. In the Netherlands, where roughly 5% of surnames begin with &#8220;van&#8221; and another 5% with &#8220;de,&#8221; the distribution would be far from uniform.</p>

<p>Figure 10.6 uses a simple hash function (recall that <code>i%j</code> returns the remainder when the integer <code>i</code> is divided by the integer <code>j</code>) to implement a dictionary with integers as keys.</p>

<p>The basic idea is to represent an instance of class <code>intDict</code> by a list of <strong>hash buckets</strong>, where each bucket is a list of key/value pairs. By making each bucket a list, we handle collisions by storing all of the values that hash to the same bucket in the list.</p>

<p>The hash table works as follows: The instance variable <code>buckets</code> is initialized to a list of <code>numBuckets</code> empty lists. To store or look up an entry with key <code>dictKey</code>, we use the hash function <code>%</code> to convert <code>dictKey</code> into an integer, and use that integer to index into <code>buckets</code> to find the hash bucket associated with <code>dictKey</code>. We then search that bucket (which is a list) linearly to see if there is an entry with the key <code>dictKey</code>. If we are doing a lookup and there is an entry with the key, we simply return the value stored with that key. If there is no entry with that key, we return <code>None</code>. If a value is to be stored, then we either replace the value in the existing entry, if one was found, or append a new entry to the bucket if none was found.</p>

<p>There are many other ways to handle collisions, some considerably more efficient than using lists. But this is probably the simplest mechanism, and it works fine if the hash table is big enough and the hash function provides a good enough approximation to a uniform distribution.</p>

<p>Notice that the <code>__str__</code> method produces a representation of a dictionary that is unrelated to the order in which elements were added to it, but is instead ordered by the values to which the keys happen to hash. This explains why we can't predict the order of the keys in an object of type <code>dict</code>.</p>

<p><strong>Figure 10.6 Implementing dictionaries using hashing</strong></p>

<pre><code class="language-python">class intDict(object):
    """A dictionary with integer keys"""

    def __init__(self, numBuckets):
        """Create an empty dictionary"""
        self.buckets = []
        self.numBuckets = numBuckets
        for i in range(numBuckets):
            self.buckets.append([])

    def addEntry(self, dictKey, dictVal):
        """Assumes dictKey an int. Adds an entry."""
        hashBucket = self.buckets[dictKey%self.numBuckets]
        for i in range(len(hashBucket)):
            if hashBucket[i][0] == dictKey:
                hashBucket[i] = (dictKey, dictVal)
                return
        hashBucket.append((dictKey, dictVal))

    def getValue(self, dictKey):
        """Assumes dictKey an int. Returns entry associated
           with the key dictKey"""
        hashBucket = self.buckets[dictKey%self.numBuckets]
        for e in hashBucket:
            if e[0] == dictKey:
                return e[1]
        return None

    def __str__(self):
        result = '{'
        for b in self.buckets:
            for e in b:
                result = result + str(e[0]) + ':' + str(e[1]) + ','
        return result[:-1] + '}' #result[:-1] omits the last comma</code></pre>

</section>

<p>The text goes on to show a further example and explanation of how the <code>intDict</code> works.</p>
<p>The selection above does depend on knowing something about what &#8220;constant time&#8221; means, and possibly &#8220;immutable.&#8221; But if you were reading the book, you would have learned these already.</p>
<p>The organization and exposition is really extraordinary. Even in just the small hashing section above, there&#8217;s a sequence of three or four concrete examples to motivate the thinking, and then it leads into an understandable implementation. This is phenomenal educational writing.</p>
<p>This is <a href="http://mitpress.mit.edu/books/introduction-computation-and-programming-using-python-0">the book</a> for people who want to learn.</p>    
    ]]></description>
<link>http://planspace.org/20150111-a_great_python_book_explains_hash_tables/</link>
<guid>http://planspace.org/20150111-a_great_python_book_explains_hash_tables/</guid>
<pubDate>Sun, 11 Jan 2015 12:00:00 -0500</pubDate>
</item>
<item>
<title>Learn to Code with Emacs</title>
<description><![CDATA[

<p>To <a href="/20141231-two_problems_with_learn-to-code_sites/">learn to code</a> effectively, use:</p>
<ul>
<li>tools that are actually used for coding</li>
<li>materials that are reusable as references</li>
</ul>
<p>Here's one way to do it:</p>
<ol>
<li><a href="http://emacs.link/">Install Emacs</a>.</li>
<li>Do the built-in Emacs Tutorial, accessible from the start screen.</li>
<li>Learn about the Info system (C-h i, select Info).</li>
<li>Work through the Introduction to Programming Emacs Lisp.</li>
</ol>
<p>These steps will all make sense if you do them in order.</p>
<p>Here's what you get, if you follow the steps above:</p>
<ul>
<li>a powerful editor that you can use with any programming language</li>
<li>programming skills together with computer science concepts</li>
<li>the ability to use that programming language to enhance that editor</li>
</ul>
<p>This is a powerful combination, and one that blends seamlessly into further learning and productive work.</p>    
    ]]></description>
<link>http://planspace.org/20150101-learn_to_code_with_emacs/</link>
<guid>http://planspace.org/20150101-learn_to_code_with_emacs/</guid>
<pubDate>Thu, 01 Jan 2015 12:00:00 -0500</pubDate>
</item>
<item>
<title>Two Problems with Learn-to-Code Sites</title>
<description><![CDATA[

<p>Lots of people want to learn to code, and this is good. But lots of the web sites that want to teach people to code are bad.</p>
<p>The popular learn-to-code sites generally teach a popular language, which is not necessarily a bad thing.</p>
<p>But there are two fundamental problems with the approach of many popular sites:</p>
<ol>
<li>They teach all inside a browser. This removes setup difficulty by providing a custom toy environment but leaves the student with no independent working setup of their own.</li>
<li>They take a one pass adventure game guided tour approach. This enforces a progression and generally makes it difficult or impossible to scan through and refer back to the material.</li>
</ol>
<p>There is definitely value in making it easy for people to try something they otherwise wouldn't try. After trying, a different approach may be better for facilitating learning.</p>
<p>To learn to code effectively, use:</p>
<ol>
<li>tools that are actually used for coding</li>
<li>materials that are reusable as references</li>
</ol>
<p>This means that you should:</p>
<ol>
<li>use an editor and language implementation installed on your own machine</li>
<li>have, read, and work from one or more good documents, guides, or books</li>
</ol>
<p>Books are a really good idea. This should be obvious, but it seems, especially when it comes to technology, that people want to imagine you can "learn by doing" everything, starting from nothing and then just checking Stack Overflow occasionally. No. Read a book. It's a mistake in an in-person class to think that you can get by without reading a book. You should read a book. It's also a mistake to think you can get by with just online activities. Get a book.</p>
<p>The "toy environment" and "guided tour" design problems of most online learn-to-code systems are fundamental problems. It additionally seems to be, too frequently, that the materials presented in these systems are less well organized and produced than one would expect from a book. Further, the interactive exercises that are ostensibly a major advantage of online systems can totally break the experience if they have the tiniest blocking error in design or implementation. And finally projects, which are an excellent way to learn, too often feel inane and constricting rather than interesting and eye-opening when forced into the frameworks of automated systems.</p>    
    ]]></description>
<link>http://planspace.org/20141231-two_problems_with_learn-to-code_sites/</link>
<guid>http://planspace.org/20141231-two_problems_with_learn-to-code_sites/</guid>
<pubDate>Wed, 31 Dec 2014 12:00:00 -0500</pubDate>
</item>
<item>
<title>Use Info in Emacs</title>
<description><![CDATA[

<p>There is a documentation system accessible from <a href="http://www.gnu.org/software/emacs/">Emacs</a> called <a href="https://www.gnu.org/software/texinfo/">Info</a>. Here's advice from a parenthetical in the <a href="http://www.gnu.org/software/emacs/manual/html_mono/eintr.html#Note-for-Novices">Note for Novices</a> of <a href="www.gnu.org/software/emacs/manual/html_mono/eintr.html">An Introduction to Programming in Emacs Lisp</a>:</p>
<blockquote>
<p>"To learn about Info, type C-h i and then select Info."</p>
</blockquote>
<p>Despite using Emacs, off and on, for many years, and also more recently hearing <a href="http://sachachua.com/">Sacha Chua</a> recommend Info in her <a href="http://sachachua.com/blog/category/podcast/emacs-chat-podcast/">Emacs chats</a>, I had never really used the Info system. But something on <a href="http://www.johndcook.com/blog/">John Cook</a>'s blog pointed me to the <a href="www.gnu.org/software/emacs/manual/html_mono/eintr.html">intro to Emacs Lisp</a> and I started reading it in a web browser until I got to that part:</p>
<blockquote>
<p>"To learn about Info, type C-h i and then select Info."</p>
</blockquote>
<p>At that point I did. I went into Emacs and learned about Info, and then I continued working through the <a href="www.gnu.org/software/emacs/manual/html_mono/eintr.html">intro to Emacs Lisp</a> inside Emacs, which was a much better way to read it than inside a browser.</p>
<p>I wish I'd come to all this sooner.</p>
<p>If you'd like to try Emacs, you should find it <a href="http://planspace.org/20141207-make_it_easy_to_install_emacs/">easy to install</a> using <a href="http://emacs.link/">emacs.link</a>. Once you have Emacs open on your computer, do the built-in tutorial. Then:</p>
<blockquote>
<p>"To learn about Info, type C-h i and then select Info."</p>
</blockquote>
<p>And then check out the Introduction to Emacs Lisp, also in the Info system.</p>
<p>Have fun!</p>    
    ]]></description>
<link>http://planspace.org/20141230-use_info_in_emacs/</link>
<guid>http://planspace.org/20141230-use_info_in_emacs/</guid>
<pubDate>Tue, 30 Dec 2014 12:00:00 -0500</pubDate>
</item>
<item>
<title>Calendar Plots should be Easy</title>
<description><![CDATA[

<p>Popularized by Mike Bostock's <a href="http://bl.ocks.org/mbostock/4063318">example</a> and the GitHub <a href="https://github.com/blog/1360-introducing-contributions">contribution calendar</a>, calendar plots have some recognition now.</p>
<p><a href="http://bit.ly/NYCsubway"><img alt="" src="calendar.png"></a></p>
<p>Calendar plots can be very good for showing daily data over time when weekly, monthly, and yearly structure are relevant. While color is not ideal for conveying numeric data, patterns can be made quickly discernible and interaction can add table lookup functionality.</p>
<p>I've made plots like <a href="http://bit.ly/NYCsubway">this</a> myself, but it has required fiddling with HTML, CSS, and JavaScript in typical <a href="http://d3js.org/">D3</a> fashion. There are some tools for making it easier to build these plots, like the <a href="http://kamisama.github.io/cal-heatmap/v2/">Cal-Heatmap</a> JavaScript plugin and the Google Charts <a href="https://developers.google.com/chart/interactive/docs/gallery/calendar">Calendar Chart</a>, but even with these it's still an HTML/JavaScript affair.</p>
<p>I want to be able to do something like this in <a href="http://www.r-project.org/">R</a> and get an interactive calendar plot:</p>
<pre><code class="language-r"># this package does not (yet) exist
library(plotcal)
plot.cal(values, dates)</code></pre>

<p>I want to be able to do something like this in <a href="https://www.python.org/">Python</a> and get an interactive calendar plot:</p>
<pre><code class="language-python"># this package does not (yet) exist
from plot_cal import plot_cal
plot_cal(values, dates)</code></pre>

<p>Such functionality could also interact more closely with <code>data.frame</code>s/<code>DataFrame</code>s, tuples, maps/dicts, etc. That would be fine.</p>
<p>Somebody should make such functions, or extend some existing packages to include them. Or if such things already exist, somebody should just tell me about it. Either way, I will say thank you.</p>    
    ]]></description>
<link>http://planspace.org/20141229-calendar_plots_should_be_easy/</link>
<guid>http://planspace.org/20141229-calendar_plots_should_be_easy/</guid>
<pubDate>Mon, 29 Dec 2014 12:00:00 -0500</pubDate>
</item>
<item>
<title>How does R calculate histogram break points?</title>
<description><![CDATA[

<p>Break points make (or break) your histogram. <a href="http://www.r-project.org/">R</a>'s default algorithm for calculating histogram break points is a little interesting. Tracing it includes an unexpected dip into R's <a href="http://en.wikipedia.org/wiki/C_%28programming_language%29">C</a> implementation.</p>
<pre><code class="language-r"># set seed so "random" numbers are reproducible
set.seed(1)
# generate 100 random normal (mean 0, variance 1) numbers
x &lt;- rnorm(100)
# calculate histogram data and plot it as a side effect
h &lt;- hist(x, col="cornflowerblue")</code></pre>

<p><img alt="" src="histogram.png"></p>
<p>The <code>hist</code> function calculates and returns a histogram representation from data. That calculation includes, by default, choosing the break points for the histogram. In the example shown, there are ten bars (or bins, or cells) with eleven break points (every 0.5 from -2.5 to 2.5). With break points in hand, <code>hist</code> counts the values in each bin. The histogram representation is then shown on screen by <code>plot.histogram</code>.</p>
<p>(By default, bin counts include values less than or equal to the bin's right break point and strictly greater than the bin's left break point, except for the leftmost bin, which includes its left break point.)</p>
<p>The choice of break points can make a big difference in how the histogram looks. Badly chosen break points can obscure or misrepresent the character of the data. R's default behavior is not particularly good with the simple data set of the integers 1 to 5 (as pointed out by <a href="https://twitter.com/hadleywickham">Wickham</a>).</p>
<pre><code class="language-r">hist(1:5, col="cornflowerblue")</code></pre>

<p><img alt="" src="bad5.png"></p>
<p>A manual choice like the following would better show the evenly distributed numbers.</p>
<pre><code class="language-r">hist(1:5, breaks=0.5:5.5, col="cornflowerblue")</code></pre>

<p><img alt="" src="good5.png"></p>
<p>It might be even better, arguably, to use more bins to show that not all values are covered.</p>
<pre><code class="language-r">hist(1:5, breaks=seq(0.55, 5.55, 0.1), col="cornflowerblue")</code></pre>

<p><img alt="" src="better5.png"></p>
<p>In any event, break points matter. When exploring data it's probably best to experiment with multiple choices of break points. But in practice, the defaults provided by R get seen a lot.</p>
<p>So how does R choose break points?</p>
<p>By default, inside of <code>hist</code> a two-stage process will decide the break points used to calculate a histogram:</p>
<ol>
<li>
<p>The function <code>nclass.Sturges</code> receives the data and returns a recommended number of bars for the histogram. The documentation says that <a href="http://en.wikipedia.org/wiki/Histogram#Number_of_bins_and_width">Sturges' formula</a> is "implicitly basing bin sizes on the range of the data" but it's just based on the number of values, as <code>ceiling(log2(length(x)) + 1)</code>. This is really fairly dull.</p>
</li>
<li>
<p>Then the data and the recommended number of bars gets passed to <code>pretty</code> (usually <code>pretty.default</code>), which tries to "Compute a sequence of about n+1 equally spaced &#8216;round&#8217; values which cover the range of the values in x. The values are chosen so that they are 1, 2 or 5 times a power of 10." This ends up calling into some parts of R implemented in C, which I'll describe a little below.</p>
</li>
</ol>
<p>Note: In what follows I'll link to a <a href="https://github.com/wch/r-source/tree/34c4d5dd3493863f6665f907dbad9bf1d800c0d4">mirror</a> of the R <a href="https://svn.r-project.org/R/">sources</a> because <a href="https://github.com/">GitHub</a> has a nice, familiar interface. I'll point to the most recent version of files without specifying line numbers. You'll want to search within the files to what I'm talking about. To see exactly what I saw go to commit <a href="https://github.com/wch/r-source/tree/34c4d5dd3493863f6665f907dbad9bf1d800c0d4">34c4d5dd</a>.</p>
<p>The <a href="https://github.com/wch/r-source/blob/trunk/src/library/grDevices/R/calc.R">source</a> for <code>nclass.Sturges</code> is trivial R, but the <code>pretty</code> <a href="https://github.com/wch/r-source/blob/trunk/src/library/base/R/pretty.R">source</a> turns out to get into C. I hadn't looked into any of R's C implementation before; here's how it seems to fit together:</p>
<p>The source for <code>pretty.default</code> is straight R until:</p>
<pre><code class="language-r">z &lt;- .Internal(pretty( # ... cut</code></pre>

<p>This <code>.Internal</code> thing is a call to something written in C. The file <a href="https://github.com/wch/r-source/blob/trunk/src/main/names.c">names.c</a> can be useful for figuring out where things go next. We find this line:</p>
<pre><code class="language-c">{"pretty",    do_pretty,  0,  11, 7,  {PP_FUNCALL, PREC_FN,   0}},</code></pre>

<p>So it goes to a C function called <code>do_pretty</code>. That can be found in <a href="https://github.com/wch/r-source/blob/trunk/src/main/util.c">util.c</a>. This is a lot of very Lisp-looking C, and mostly for handling the arguments that get passed in. For example:</p>
<pre><code class="language-c">    int n = asInteger(CAR(args)); args = CDR(args);</code></pre>

<p>That's kind of neat, but the actual work is done somewhere else again. The body of <code>do_pretty</code> calls a function <code>R_pretty</code> like this:</p>
<pre><code class="language-c">    R_pretty(&amp;l, &amp;u, &amp;n, min_n, shrink, REAL(hi), eps, 1);</code></pre>

<p>The call is interesting because it doesn't even use a return value; <code>R_pretty</code> modifies its first three arguments in place. Gross.</p>
<p>The function <code>R_pretty</code> is in its own file, <a href="https://github.com/wch/r-source/blob/trunk/src/appl/pretty.c">pretty.c</a>, and finally the break points are made to be "nice even numbers" and there's a result.</p>
<p>I was surprised by where the code complexity of this process is.</p>    
    ]]></description>
<link>http://planspace.org/20141225-how_does_r_calculate_histogram_break_points/</link>
<guid>http://planspace.org/20141225-how_does_r_calculate_histogram_break_points/</guid>
<pubDate>Thu, 25 Dec 2014 12:00:00 -0500</pubDate>
</item>
<item>
<title>DC Voter Registration Data</title>
<description><![CDATA[

<p><em>This is an expanded account; see <a href="https://github.com/ajschumacher/dc_voter_reg">dc_voter_reg</a> on GitHub for the data and concise documentation.</em></p>
<p><img alt="" src="cd.jpg"></p>
<p>DC voter registration data is public, but not very easy to get.</p>
<p>On Thursday, December 18, 2014, I took a printed copy of a <a href="http://www.dcboee.org/pdf_files/Data_Request_Form.pdf">PDF form</a> that I found on the <a href="http://www.dcboee.org/">DC Board of Elections web site</a> to 441 4th Street NW, suite 250 north, Washington, DC, 20001. I had to show ID, have my bag x-rayed, and go through a metal detector to get into the building.</p>
<p>I brought my checkbook so I could pay $2 for a CD-ROM of voter registration data. The clerk informed me that the data is updated daily. She burned my CD while I waited. She told me there are no rules on how the data can be used. I take it to be public domain.</p>
<p>On the CD were two files:</p>
<ul>
<li>The data was in a Microsoft Access database file called <code>DC VH EXPORT.MDB</code> (154 MB). I bought a PC laptop running Windows 8, purchased and installed Microsoft Access, opened the file and exported the data as text. It comes out as 130 megabytes of uncompressed text. I was able to get the column headers out and stick them on top of the file so that it can be read as nice CSV. Zipped (using the Windows built-in) the result is the 20 MB <a href="https://github.com/ajschumacher/dc_voter_reg/blob/master/20141218-dc_voters.csv.zip">20141218-dc_voters.csv.zip</a>.</li>
<li>The provided documentation file was a plain text <code>Read Me.txt</code>. I renamed this to <a href="https://github.com/ajschumacher/dc_voter_reg/blob/master/20141218-dc_voters.txt">20141218-dc_voters.txt</a>. It seems slightly out of date with respect to the data in that the later columns corresponding to elections are not the same in the documentation and in the data. These column names are interpretable as MMYYYY-T, I believe, where MM is numeric month, YYYY is four-digit year, and T is a letter corresponding to election type. I think G is General and P is primary.</li>
</ul>
<p>You can also get voter registration data on a per-ward basis in Microsoft Access or Excel formats. They will email it to you, but you have to fax in the form to make this request. I wonder if they would accommodate daily requests for every ward's data. It seems like it would be much less annoying to just put the data online automatically; it isn't even very heavy. If we dream big, maybe the data could live in <a href="http://dat-data.com/">dat</a>? Any option that doesn't require making a physical visit to their office during their fairly narrow business hours would be an improvement. Any format that doesn't require purchasing proprietary software would be an improvement.</p>
<p>Another thing you can get is images (PDFs?) of signatures for nominating petitions and ballot measures. You pay just $2 per CD-ROM, but these are only available during ten-day "challenge periods." So keep your eyes peeled! I haven't seen what these things look like.</p>
<p>At least you can get nice maps like this (or for individual wards) for just $10 each:</p>
<p><img alt="" src="map.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20141220-dc_voter_registration_data/</link>
<guid>http://planspace.org/20141220-dc_voter_registration_data/</guid>
<pubDate>Sat, 20 Dec 2014 12:00:00 -0500</pubDate>
</item>
<item>
<title>Please stop saying “Big Data”</title>
<description><![CDATA[

<p><em>A short talk for <a href="http://www.air.org/">AIR</a>.</em></p>
<p>I thought about calling this &#8220;Size and Complexity in Real Data Systems,&#8221; but that would have been so boring.</p>
<hr>
<p><img alt="" src="alan_kay.jpg"></p>
<hr>
<p>This is <a href="http://en.wikipedia.org/wiki/Alan_Kay">Alan Kay</a>. He worked at Xerox PARC, he said &#8220;The best way to predict the future is to invent it,&#8221; and he said this, at a <a href="https://www.youtube.com/watch?v=gTAghAJcO1o">talk</a> earlier this year:</p>
<blockquote>
<p>Big data is a way that a lot of people are trying to make money today. And it's a favorite of marketing people, because it's in the wind. Everybody has heard the phrase &#8220;big data.&#8221; Not everybody knows what it means. And so it's the perfect context for doing things that people can say, &#8220;Well this is an application of big data and this is an application of big data.&#8221; But in fact, the interesting future's not about data at all&#8212;it's about meaning.</p>
</blockquote>
<p>The objection here, which is an objection of many, is an objection to torturing the phrase &#8220;Big Data&#8221; until it means everything and nothing.</p>
<p>You can also read an article that Deloitte published last Wednesday on the Wall Street Journal's web site called <a href="http://deloitte.wsj.com/cio/2014/12/10/should-we-stop-using-the-term-big-data/">Should We Stop Using the Term &#8216;Big Data&#8217;?</a>.</p>
<p>The answer is yes. Let's all stop saying &#8220;big data&#8221; when we just mean &#8220;data.&#8221;</p>
<hr>
<p><img alt="" src="excel.png"></p>
<hr>
<p>Some people think big data is data they can't put in Excel. The problem with this is that you shouldn't be putting <em>any</em> data in Excel. There are many reasons Excel is bad. If you care about getting the right answer, you shouldn't use Excel [1]. But it is also true that more and more, we've moved from the era of &#8220;shouldn't use Excel&#8221; to the era of &#8220;can't possibly use Excel.&#8221;</p>
<p>The reasons you can't use Excel these days can include volume, velocity, variety, and veracity, those <a href="http://www.ibmbigdatahub.com/infographic/four-vs-big-data">V words</a> that buzz along with &#8220;big data.&#8221; These Vs are trying to get people to realize that their ideas about how to work with data are inadequate. The ideas were inadequate before as well, but now they're really clearly inadequate. It is more comfortable to think that the problem is only with these new-seeming Vs.</p>
<p>[1]: <em>See, for example, <a href="http://www.businessweek.com/articles/2013-04-18/faq-reinhart-rogoff-and-the-excel-error-that-changed-history">Growth in a Time of Debt</a>.</em></p>
<hr>
<p><img alt="" src="data_flow.jpg"></p>
<hr>
<p>Working with data is always about building systems. This includes systems where the output is an analysis result. You need to build systems that are testable, reusable, extensible, and composable. Ideally, systems that are elegant. You can't do that with Excel, or with most commercial statistical offerings. To steal some other peoples' language, <a href="http://www.wsj.com/articles/SB10001424053111903480904576512250915629460">software is eating the world</a> and you need to <a href="http://www.rushkoff.com/program-or-be-programmed/">program or be programmed</a>.</p>
<p>What should you learn, if all you know is Excel or something similarly unfortunate like Stata or SAS? If you think you should learn <a href="http://www.r-project.org/">R</a> or <a href="http://clojure.org/">Clojure</a> or <a href="http://www.scala-lang.org/">Scala</a>, you might be right. Otherwise, learn <a href="https://www.python.org/">Python</a>.</p>
<hr>
<p><img alt="" src="big_data.png"></p>
<hr>
<p>This is a <a href="http://people.cs.umass.edu/~mcgregor/stocworkshop/langford.pdf">slide</a> from <a href="http://en.wikipedia.org/wiki/John_Langford_%28computer_scientist%29">John Langford</a>, who has worked on large scale machine learning problems at Yahoo! and Microsoft. This is what technical people tend to mean by &#8220;big data.&#8221;</p>
<p>It's not quite the same thing as being &#8220;O(n<sup>2</sup>) algorithm feasible,&#8221; but to put it differently, let's say that some small data you could theoretically work with in Excel.</p>
<p>Medium data might fit on one computer, but to work with it you'll probably need someone who knows what &#8220;O(n<sup>2</sup>)&#8221; means. She started programming years before you, and you probably want her working on your small data too.</p>
<p>Very few people have big data by the definition here, and that's okay [2].</p>
<p>Second recommendation: if you do have really big data, learn <a href="https://spark.apache.org/">Spark</a>.</p>
<p>[2]: <em>Everybody can get access to somebody else's big data, often public, but very few people are producing their own big data.</em></p>
<hr>
<p><img alt="" src="unreasonable_data.png"></p>
<hr>
<p>Is more data better? This question is distinct from the question of whether our data is big. Do we want more data at all?</p>
<p>In 2009, some folks at Google come out with <a href="http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/35179.pdf">The Unreasonable Effectiveness of Data</a>. They seem to be saying that there is at least one case in which the answer is yes, we want more data.</p>
<hr>
<p><img alt="" src="scaling_corpora.png"></p>
<hr>
<p>A good illustration of their point is a <a href="http://dl.acm.org/citation.cfm?id=1073017">2001 Microsoft paper</a>. The problem here is called &#8220;confusion set disambiguation,&#8221; which sounds fancy but just means that the model has to decide whether to fill in a blank in a sentence with T-O to, T-O-O too, or T-W-O two. So the data is text, and the point is that the amount of data seems to be more important than the choice of algorithm. There are three things to say here.</p>
<p>First, is this big data? Their complete data set was a billion words. Around five gigabytes. This is not an example of big data; that fits on a memory stick.</p>
<p>Second, how are we measuring effectiveness? This is an important thing to take from this example. The Y axis is prediction accuracy on a test set. The model sees some training data, and then we ask it to predict for separate test data, and we see how often it's right. This is a predictive framing of the problem, which is powerful. It's the scientific method: the model is correct to the extent it makes correct predictions. But it doesn't make much sense to try to interpret these models in any way that would please a traditional linguist.</p>
<p>Finally, should we be surprised that having more data helps for this problem?</p>
<p>The problem is a natural language problem. Language is complicated. The problem has been simplified quite a lot, to just confusion set disambiguation, but there are a lot of words, and all these models are high variance, meaning roughly that they have a ton of coefficients [3]. So even if you have a lot of data, you may still have relatively little (or even none) for some cases.</p>
<p>So it makes sense that these models should do better when they get to study more text. And text is easy to get from the internet, so there's no reason not to throw more data at the problem.</p>
<p>Not all problems are like this.</p>
<p>[3]: <em><a href="http://xavier.amatriain.net/">Xavier Amatriain</a> (formerly of Netflix) has a good <a href="http://technocalifornia.blogspot.com/2012/07/more-data-or-better-models.html">explanation</a> of this which inspired this section.</em></p>
<hr>
<p><img alt="" src="big_complex.png"></p>
<hr>
<p>I've tried to separate bigness from other kinds of data complexity. Where in this space can we operate?</p>
<hr>
<p><img alt="" src="big_complex_possible.png"></p>
<hr>
<p>I don't know if this is a perfect sketch, but there's some truth to it. Simple problems are common and now relatively easy to scale with the big name technologies that people like to sell.</p>
<p>A criticism of this graph is that it's a little circular, in that I'm kind of implicitly saying that things that can be scaled are simple. Maybe so. But there are problems that don't scale even in theory, and there are also problems that have no current good solution at any scale, and the number one way to make a complex problem scale is to transform it into a simple problem.</p>
<p>The amazing thing that you encounter in practice though is how much work there is still to be done here in the lower left-hand corner of this graph, and the tendency of organizations to take their easy problems and make them more complicated.</p>
<hr>
<p>TSDL</p>
<hr>
<p>Here's an example that I didn't work on; I only witnessed it from a distance. TSDL stands for Teacher Student Data Linkage. So say you're a company like AIR and you have to decide, for a state, who's a good teacher based on how their students did. (That's hard, by the way.)</p>
<p>You need, of course, some Teacher Student Data Linkage data. Certainly the school districts in the state have this, right?</p>
<p>Well, no. In the case of at least one large urban school district, they did not have usable information of this type. What they did have was two systems that each had some overlapping information. This was arguably already too many systems.</p>
<p>So how do they satisfy the need that the state and the company have for the linkage data? They build a third system. This third system gets data from the two existing systems, and then presents an interface for everyone in the district to go in by hand and identify their students.</p>
<p>This is a lot of work to get something that they probably should have had to begin with. But at least now that they have it, all their systems can benefit, right?</p>
<p>The data that was collected, to the best of my knowledge, was never fed back into the rest of the systems.</p>
<p>This is an example of the importance of smart engineering. For whatever reason, be it funding, vision, technical knowledge... systems are not good. They are not delivering the data that should really be expected of them, so when there's finally a clear and present need for that data, a lot of work goes into getting it,too often yielding dividends for nobody else.</p>
<p>It's not easy to set up and instrument systems, and especially hard to anticipate future needs. And the fragmentation of the American education system does not help with data integration. But if we want to benefit from better uses of data, we need to invest in better systems, not band-aid systems.</p>
<hr>
<p>Arlington Big Data Roundtable</p>
<hr>
<p>Here's an example that I did work on. The Arlington Big Data Roundtable was put on by Arlington Public Schools, and the team I was on won, and it got some <a href="http://www.washingtonpost.com/local/education/arlington-schools-announce-key-findings-from-big-data-competition/2014/09/10/fff0ee3a-3903-11e4-8601-97ba88884ffd_story.html">press</a>, which was nice.</p>
<p>What did we do? They gave us a bunch of data, and we predicted which students would drop out in the following year. Based on the historical data we had, and the success metric that we chose, we were pretty good at it. You can predict dropouts. This should be surprising to no one. So what's to say about this?</p>
<p>Let's start with the size of the data. The data in the last example wasn't big, by the way, and that was a large urban school district. Arlington has something like 20,000 students. So the only &#8220;big&#8221; here has to be some other kind of complexity.</p>
<p>You may have heard that 80% of a data scientist's time is spent munging data, leaving only 20% for analysis. It's interesting that in a data-obsessed profession this entirely made-up statistic gets quoted so much. But it feels true!</p>
<p>How is this example like the last example? We were handed data and worked entirely separately from the real host data systems. So all the work we did to make the data usable, who benefits from that? Nobody. They can't just take that and plug it in to whatever system it came from.</p>
<p>A side issue is that many of the problems come from defining what you are talking about, and bureaucracies tend to ruin this process, often by failing to provide a complete definition, sometimes deliberately. &#8220;What does it mean to drop out?&#8221; turns out to be tricky.</p>
<p>So we can predict who's going to drop out. Is that going to help any students this year? If it does, it will be because of systems-building work in larger measure than modeling work.</p>
<hr>
<p>&#1587;&#1602;&#1587;&#1602;&#1577;</p>
<hr>
<p>Google Translate tells me that this is Arabic for &#8220;tweet.&#8221;</p>
<p>This is an example from a hackathon I participated in. It gives me the opportunity to gently critique two more things: hackathons themselves, and what I'll call &#8220;data science mad-libs.&#8221;</p>
<p>Hackathons first. They're great for getting people excited and talking about something. They're hard to get results out of. So if you're clear about your goal, hackathons may be for you.</p>
<p>The hackathons that are successful tend to have goals that are either totally wide open, or very very well focused. In the first case, any interesting thing could be success. In the second, a lot of work has already gone into scoping a problem and making it attainable in the time available.</p>
<p>The deadly middle ground, which may be familiar if you've worked with clients, is a dream-like aspiration, sometimes a &#8220;data science mad-lib.&#8221;</p>
<p>Take a big problem and some big source of data, and you get a data science mad-lib:</p>
<ul>
<li>&#8220;We're going to stop human trafficking with Facebook!&#8221;</li>
<li>&#8220;We're going to end world hunger with Twitter!&#8221;</li>
<li>&#8220;We're going to monitor flu around the world with Google!&#8221;</li>
</ul>
<p>That last one has been <a href="http://www.google.org/flutrends/">done</a>, though there are <a href="http://bits.blogs.nytimes.com/2014/03/28/google-flu-trends-the-limits-of-big-data/">questions</a> about its effectiveness. Somebody may we working on these others. And wouldn't it be neat if these worked? And there may <em>be</em> a way to make them work&#8212;but these aspirations require methods. A starting point and an ending point do not imply a good path between them.</p>
<p>In the case of this particular hackathon we had quite a few Arabic tweets and the idea was to monitor socioeconomic conditions in towns in Egypt. So we put the tweets in Hadoop. Great! This gives us the illusion of making progress toward a goal. But what is our goal? How will we know if we've achieved it? We weren't sure, and while the exercise was interesting, we didn't have any usable results after our one day of work.</p>
<p>Now the <a href="http://www.unglobalpulse.org/">UN Global Pulse</a> is working on doing things like this Twitter exercise, and they may have some success. I don't want to nay-say all crazy-sounding ideas. Crazy ideas are some of my favorites. But crazy ideas that work are like magic tricks: they're only mysterious if you don't know what's really going on.</p>
<hr>
<p>data</p>
<hr>
<p>I am hopeful about data. I think we need more people working on data with more effective tools and practices. Dream big but write code. You can start writing Python tonight. Another book I recommend is called <a href="https://pragprog.com/the-pragmatic-programmer">The Pragmatic Programmer</a>.</p>
<hr>
<p>Thank you!</p>
<hr>
<p>And of course, you're under no obligation to agree with me.</p>    
    ]]></description>
<link>http://planspace.org/20141215-please_stop_saying_big_data/</link>
<guid>http://planspace.org/20141215-please_stop_saying_big_data/</guid>
<pubDate>Mon, 15 Dec 2014 12:00:00 -0500</pubDate>
</item>
<item>
<title>Make it Easy to Install Emacs</title>
<description><![CDATA[

<p>&#8220;GNU Emacs is an extensible, customizable text editor&#8212;and more.&#8221;</p>
<p>I wanted to invite novice hackers to check out <a href="http://www.gnu.org/software/emacs/">Emacs</a>. But installing Emacs for the first time isn't easy! Or rather: the installation can be easy, but finding the right package for your system may not be.</p>
<p>So I made <a href="http://emacs.link/">emacs.link</a>, a static site hosted with GitHub pages (<a href="https://github.com/ajschumacher/emacs.link">repo</a>). It does a rough system detection and then presents simple, direct installation directions.</p>
<p>The directions are opinionated in that they only show one method per system:</p>
<ul>
<li>On Linux you might want to build Emacs from source, but I don't mention that alternative.</li>
<li>On a Mac, you might prefer to install Emacs using <a href="http://brew.sh/">brew</a>, but if you don't have brew installed already it's easier to skip that step.</li>
<li>There's no Emacs installer for <a href="http://ftpmirror.gnu.org/emacs/windows/README">Windows</a>. The current directions may be too difficult for some Windows users.</li>
<li>There are ways to try to get Emacs running on <a href="http://gamma-level.com/iphoneos/ports/emacs">iOS</a> and <a href="https://play.google.com/store/apps/details?id=com.zielm.emacs">Android</a>, but I'm not sure that's even a good idea, so on mobile I recommend watching some fun <a href="https://www.youtube.com/watch?v=TMoPuv-xXMM&amp;index=6&amp;list=UUkRmQ_G_NbdbCQMpALg6UPg">Emacs videos</a>.</li>
</ul>
<p>I tried to make <a href="http://emacs.link/">emacs.link</a> attractive, after the fashion of hip startup sites. The nice background image is courtesy of <a href="https://www.flickr.com/photos/anschieber/">Andrea Schieber</a>, who released <a href="https://www.flickr.com/photos/anschieber/6303932505">the original</a> on Flickr with a Creative Commons license (<a href="https://creativecommons.org/licenses/by-nc-sa/2.0/">CC BY-NC-SA 2.0</a>). Thanks very much to her! I cropped and edited the original a little bit with <a href="http://www.gimp.org/">GIMP</a>. As required, the edited version has the same license.</p>    
    ]]></description>
<link>http://planspace.org/20141207-make_it_easy_to_install_emacs/</link>
<guid>http://planspace.org/20141207-make_it_easy_to_install_emacs/</guid>
<pubDate>Sun, 07 Dec 2014 12:00:00 -0500</pubDate>
</item>
<item>
<title>Ruby Symbols are not Lisp Symbols</title>
<description><![CDATA[

<p>I heard about <a href="http://www.johndcook.com/blog/2012/03/28/how-emacs-influenced-ruby/">How Emacs influenced Ruby</a> and the main thing I took from it was the possible connection between (Emacs) Lisp symbols and Ruby symbols, <a href="http://ergoemacs.org/emacs/Matz_Ruby_how_emacs_changed_my_life.html">as suggested by Xah</a>. But Ruby symbols and Lisp symbols are really quite different.</p>
<p>In Ruby you write a symbol starting with a colon. This looks similar to writing an apostrophe before a symbol in Lisp to quote it.</p>
<pre><code class="language-ruby"># Ruby
:aaron         # This is a symbol.
               # It is written and displayed with a leading colon.
# =&gt; :aaron</code></pre>

<pre><code class="language-lisp">; Lisp
'aaron         ; This is shorthand for the next line.
(quote aaron)  ; These both evaluate to the symbol itself, as shown.
; =&gt; aaron</code></pre>

<p>The big difference is that in Lisp, symbols evaluate as variables and functions. That's why you have to quote a symbol in Lisp to work with the symbol itself. In Ruby, on the other hand, symbols never evaluate to anything else. Variable and method names in Ruby are not symbols; they're off in their own world. Note the differing error messages here:</p>
<pre><code class="language-ruby"># Ruby
aaron        # This is not a symbol but evaluates as a variable or method.
# =&gt; NameError: undefined local variable or method `aaron' for main:Object</code></pre>

<pre><code class="language-lisp">; Lisp
aaron        ; This is a symbol which will (try to) evaluate as a variable.
; =&gt; *** Eval error ***  Symbol's value as variable is void: aaron</code></pre>

<p>You can't set (or bind) a Ruby symbol to a value at all&#8212;it's a syntax error. But that's exactly what you do in Lisp.</p>
<pre><code class="language-ruby"># Ruby
:aaron = 12       # This attempts to set a symbol to 12, which Ruby hates.
# =&gt; SyntaxError: (irb):10: syntax error, unexpected '=', expecting end-of-input</code></pre>

<pre><code class="language-lisp">; Lisp
(set 'aaron 12)   ; This sets a symbol's value as a variable to 12.
; =&gt; 12</code></pre>

<p>Conversely, what works naturally in Ruby is nonsense in Lisp.</p>
<pre><code class="language-ruby"># Ruby
aaron = 27        # This sets a variable to 27.
# =&gt; 12</code></pre>

<pre><code class="language-lisp">; Lisp
(set aaron 27)    ; This attempts to set 12 to 27.
; =&gt; *** Eval error ***  Wrong type argument: symbolp, 12</code></pre>

<p>Deeper differences between Lisp and Ruby are evident, for example, in the behavior of <code>eval</code>. In Ruby, <code>eval</code> takes a string, while in Lisp, it takes a Lisp object. So while it's true that in Ruby <code>eval(:aaron.to_s)</code> will give the variable <code>aaron</code>'s value, it's fairly unrelated to the symbol <code>:aaron</code>, and quite different from <code>(eval aaron)</code> in Lisp.</p>
<p>Some uses of Ruby and Lisp symbols are similar, but by and large trying to think of them as related was doing me more harm than good.</p>
<p>I found that <a href="https://twitter.com/chneukirchen">Christian Neukirchen</a> has <a href="http://chneukirchen.org/blog/archive/2005/12/ruby-symbols-are-not-lisp-symbols.html">a 2005 post with the same name as this one</a>, which points out even more differences between Lisp symbols and Ruby symbols. His link to the Common Lisp HyperSpec "K" glossary page (for "keyword") is broken; here's <a href="http://www.lispworks.com/documentation/HyperSpec/Body/26_glo_k.htm">a working one</a>. I'm playing with <a href="http://en.wikipedia.org/wiki/Emacs_Lisp">Emacs Lisp</a> here, not <a href="http://en.wikipedia.org/wiki/Common_Lisp">Common Lisp</a>. There may be more to be said.</p>    
    ]]></description>
<link>http://planspace.org/20141129-ruby_symbols_are_not_lisp_symbols/</link>
<guid>http://planspace.org/20141129-ruby_symbols_are_not_lisp_symbols/</guid>
<pubDate>Sat, 29 Nov 2014 12:00:00 -0500</pubDate>
</item>
<item>
<title>Alan Kay on Big Data</title>
<description><![CDATA[

<p>During his recent <a href="https://github.com/papers-we-love/papers-we-love">Papers We Love</a> DC <a href="http://www.meetup.com/Papers-We-Love-DC/events/212419432/">presentation</a>, <a href="https://twitter.com/swannodette">David Nolen</a> recommended this <a href="https://www.youtube.com/watch?v=gTAghAJcO1o">talk</a> by <a href="http://en.wikipedia.org/wiki/Alan_Kay">Alan Kay</a>, which opens with his thoughts on "big data":</p>
<blockquote>
<p>Big data is a way that a lot of people are trying to make money today. And it's a favorite of marketing people, because it's in the wind. Everybody has heard the phrase &#8220;big data.&#8221; Not everybody knows what it means. And so it's the perfect context for doing things that people can say, &#8220;Well this is an application of big data and this is an application of big data.&#8221; But in fact, the interesting future's not about data at all&#8212;it's about meaning.</p>
</blockquote>
<p>You can watch the whole talk on YouTube: <a href="https://www.youtube.com/watch?v=gTAghAJcO1o">The Future Doesn't Have to Be Incremental</a></p>    
    ]]></description>
<link>http://planspace.org/20141125-alan_kay_on_big_data/</link>
<guid>http://planspace.org/20141125-alan_kay_on_big_data/</guid>
<pubDate>Tue, 25 Nov 2014 12:00:00 -0500</pubDate>
</item>
<item>
<title>Well-Used Simple Tools</title>
<description><![CDATA[

<p><em>A <a href="http://www.meetup.com/Design-Thinking-DC/events/216029412/">short talk</a> for <a href="http://www.meetup.com/Design-Thinking-DC/">Design Thinking DC</a>.</em></p>
<p>I work with data, and the tools that are unique to what I do may or may not be interesting to you. So I'm going to start with four tools that are useful for everyone.</p>
<hr>
<p><a href="http://www.usporedi.hr/novosti/je-li-ovo-najbolja-tipkovnica-svih-vremena"><img alt="" src="keyboard.png"></a></p>
<hr>
<p>Tool number one is a keyboard. You use a keyboard a lot, and you should probably use it more.</p>
<p>Steve Yegge has a 2008 <a href="http://steve-yegge.blogspot.com/2008/09/programmings-dirtiest-little-secret.html">blog post</a> about programmers who can't touch type. You wouldn't think such people existed. But just this year, in 2014, I met such a person.</p>
<p>A keyboard is probably the tool you use more than any other. Improve your typing. Then, use keyboard shortcuts so that more things become typing.</p>
<hr>
<p><a href="http://www.google.com/chrome/"><img alt="" src="chrome.png"></a></p>
<hr>
<p>Tool number two is a browser. I usually use <a href="http://www.google.com/chrome/">Chrome</a>. I want to use <a href="http://firefox.com/">Firefox</a> more, but the keyboard bindings are broken for switching tabs when you have a YouTube video up.</p>
<p>Often, you don't have to reach for the mouse to use your browser. I'll call out key combinations that work on my Mac; on other systems they're often similar.</p>
<p><code>command</code>+<code>tab</code> switches applications. <code>command</code>+<code>l</code> gives us the address bar. I'll type in my blog's domain, <code>planspace.org</code>. <code>command</code>+<code>f</code> finds in page. I want the post on <code>pca</code>. <code>esc</code> to leave the search. <code>return</code> to follow the link. <code>space</code> to page down a little.</p>
<p>Let's do it again, another way. <code>command</code>+<code>t</code> for a new tab. We want to search for <code>pca 3d</code>. <code>return</code> to search. <code>tab</code> to start exploring links. <code>down</code> to get the result we want. <code>return</code> to follow the link.</p>
<p><code>alt</code>+<code>command</code>+<code>left</code> to change tabs. <code>command</code>+<code>w</code> to close the tab. <code>command</code>+<code>l</code> to get the address bar. <code>control</code>+<code>a</code> to go to the beginning of the line. <code>control</code>+<code>k</code> to kill the line. <code>control</code>+<code>y</code> to yank it back. <code>control</code>+<code>f</code> to move forward, <code>control</code>+<code>b</code> to move back.</p>
<p>These commands are stock - I'm not using any special accessibility tools. They work not just in the browser but across many different settings. Learn them once, and you can speed up many common operations.</p>
<hr>
<p><a href="https://gmail.com/"><img alt="" src="gmail.png"></a></p>
<hr>
<p>Tool number three is email. <a href="https://gmail.com/">Gmail</a> has been getting progressively worse, but it's still the best option. You can turn off some of the bad features, and turn on keyboard shortcuts.</p>
<p>A pass through email should not take a long time. It should be distinct from work, but will integrate with task management.</p>
<p>Move through emails with <code>j</code> and <code>k</code>, open an email with <code>o</code>. <code>r</code> to reply, and do it immediately if it's a brief request. <code>[</code> to archive an email and move to the next one. Some emails don't require a response.</p>
<p>Sometimes an email represents a task, but you can't work on it until some point in the future. This is where task management is useful. I can forward (<code>f</code>) to a future date like <code>thursday@goodtodo.com</code> and the task will be tracked in the system, so I won't see it until Thursday.</p>
<p>Tasks that will take longer than two minutes get moved to task management, even if they're for today.</p>
<p>After a pass through email, the inbox should be empty.</p>
<hr>
<p><a href="https://goodtodo.com/"><img alt="" src="goodtodo.png"></a></p>
<hr>
<p>Tool number four is <a href="https://goodtodo.com/">Good Todo</a>, which is a calendared to-do list app that integrates with email. It supplements my memory by keeping track of when I need to do things, and lets me focus on just the tasks that I'll be able to accomplish in a given day. It is way better than any other to-do application I've ever seen.</p>
<p>I include brief tasks that just need to be remembered and crossed off, as well as more substantial tasks. By looking at the list for the day I can decide what to work on first and what to reschedule or reconsider.</p>
<hr>
<p>Unix philosophy</p>
<hr>
<p>The Unix philosophy describes a way of building an effective system of tools. To paraphrase Doug McIlroy:</p>
<blockquote>
<ul>
<li>Use tools that do one thing well.</li>
<li>Use tools that work together.</li>
<li>Use tools that work with text, because text is universal.</li>
</ul>
</blockquote>
<p>I think my four simple tools follow this fairly well, but they aren't ideal examples. I'll use a simple task to demonstrate further. [1]</p>
<p>[1] <em>For more on this family of tools, see <a href="http://datascienceatthecommandline.com/">Data Science at the Command Line</a> by Jeroen Janssens.</em></p>
<hr>
<p><img alt="" src="emacs.png"></p>
<hr>
<p>Right now, I'll work on this "Friday sales report" task. I'll download the Excel file. Then I'll go to the command line.</p>
<p>Step one is getting the data out of Excel format and into text. Luckily there's a package called <a href="https://csvkit.readthedocs.org/">csvkit</a>, which includes <code>in2csv</code>, which will make short work of this simple file.</p>
<pre><code class="language-html">in2csv sales.xlsx &gt; sales.csv</code></pre>

<p>Now that we have text, a whole world of tools are available. I'll take off the header row with <code>tail</code>, <code>sort</code> the rows, reduce to the unique terms and count occurrences with <code>uniq</code>, then do another sort to see things in a nice order.</p>
<pre><code class="language-html">tail +2 sales.csv | sort | uniq -c | sort -rn</code></pre>

<p>Notice the input and output are both text. I could work with this text further.</p>
<p>I'll use <code>R</code> to make a quick bar graph.</p>
<pre><code class="language-bash">cat sales.csv | Rio -ge "g+geom_bar(aes(item))" &gt; plot.png</code></pre>

<hr>
<p><img alt="" src="plot.png"></p>
<hr>
<p>In three lines, I've done fairly much, and I've done it repeatably.</p>
<p>I'm using my command line from inside <a href="http://www.gnu.org/software/emacs/">Emacs</a>, which is a text editor. [2] I'll take my three lines and make them a script. Now I can repeat what I've done whenever there's new data.</p>
<p>[2] <em>For more about Emacs, see my <a href="/20141007-emacs_python/">Emacs and Python</a> talk.</em></p>
<hr>
<p>what are good tools?</p>
<hr>
<p>Good tools have low or negative cognitive load. They are simple in what they do, and how they do it. They avoid hidden state.</p>
<p>Good tools are pure, in that they are distinct from what they operate on. They don't lock you into a closed format. They are tools, not kits.</p>
<p>Good tools are textual, programmable, repeatable, inspectable, automatable: anything you do once can be examined and repeated later non-interactively.</p>
<p>These are some of my thoughts on tooling, and I'd invite you to consider them. You could also read some of the books that have influenced me.</p>
<hr>
<p><a href="http://bitliteracy.com/"><img alt="" src="bit_literacy.jpg"></a></p>
<hr>
<p>My thoughts on email and to-do management come directly from <a href="http://bitliteracy.com/">Bit Literacy</a>, which you can get for free at <a href="http://bitliteracy.com/">bitliteracy.com</a>.</p>
<hr>
<p><a href="https://pragprog.com/the-pragmatic-programmer"><img alt="" src="pragmatic_programmer.jpg"></a></p>
<hr>
<p>My thoughts on text and separation of concerns, among other things, were certainly influenced by <a href="https://pragprog.com/the-pragmatic-programmer">The Pragmatic Programmer</a>.</p>
<hr>
<p><a href="http://37signals.com/rework/"><img alt="" src="rework.png"></a></p>
<hr>
<p><a href="http://37signals.com/rework/">ReWork</a>, which is largely the same as the freely available <a href="http://gettingreal.37signals.com/">Getting Real</a>, has a lot of good ideas for working effectively. "Do everything you can to remove layers of abstraction" is one quote I like.</p>
<hr>
<p><img alt="" src="notepad.jpg"></p>
<hr>
<p>This is an image from the drafting process for this talk. I've been strongly influenced by the <a href="http://www.bard.edu/iwt/">Bard Institute for Writing and Thinking</a>, and paper is my favorite invention. I mention this to emphasize that while I've shown certain kinds of tools, thinking in many different ways is important to everyone and multiple types of process can be useful in supporting various stages of work.</p>
<hr>
<p>use version control!</p>
<hr>
<p>The major tool I've omitted is version control. Use <a href="http://git-scm.com/">git</a>.</p>
<p>And don't use <a href="http://www.sas.com/">SAS</a>.</p>
<p>Thank you very much!</p>    
    ]]></description>
<link>http://planspace.org/20141117-well_used_simple_tools/</link>
<guid>http://planspace.org/20141117-well_used_simple_tools/</guid>
<pubDate>Mon, 17 Nov 2014 12:00:00 -0500</pubDate>
</item>
<item>
<title>A True and Delightful Incident</title>
<description><![CDATA[

<p>The mathematician Raymond Smullyan writes in the preface to his book <a href="http://en.wikipedia.org/wiki/To_Mock_a_Mockingbird">To Mock a Mockingbird</a>:</p>
<blockquote>
<p>Shortly after the publication of my first puzzle book&#8212;called <em>What Is the Name of This Book?</em>&#8212;I received a letter from an unknown female suggesting an alternative solution to one of the puzzles, which I found more elegant than the one I had given. She closed the letter with &#8220;Love&#8221; and signed her name. I had absolutely no idea who she was, or whether she was married or single. I wrote back expressing my appreciation of her solution and asked whether I might use it in a subsequent edition. I also suggested that if she had not already graduated from college she might consider majoring in mathematics, since she showed a definite mathematical talent. Shortly after, she replied: &#8220;Thank you for your gracious letter. You have my permission to use my solution. I am nine and a half years old and am in fifth grade.&#8221;</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20141107-a_true_and_delightful_incident/</link>
<guid>http://planspace.org/20141107-a_true_and_delightful_incident/</guid>
<pubDate>Fri, 07 Nov 2014 12:00:00 -0500</pubDate>
</item>
  </channel>
</rss>
