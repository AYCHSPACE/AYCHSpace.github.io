<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>plan âž” space</title>
    <link>http://planspace.org/</link>
    <description>plan space from outer nine</description>
    <language>en-us</language>
    <atom:link href="http://planspace.org/rss.xml" rel="self" type="application/rss+xml" />
<item>
<title>The Book Thing of Baltimore</title>
<description><![CDATA[

<p>I really like <a href="https://bookthing.org/">The Book Thing of Baltimore</a>. It's like a <a href="https://littlefreelibrary.org/">Little Free Library</a> but <a href="https://en.wikipedia.org/wiki/The_Book_Thing">with 200,000 books</a>. It's as great <a href="https://www.atlasobscura.com/places/the-book-thing-baltimore-maryland">as everyone says</a> and I think there should be more of them.</p>
<p><img alt="inside the book thing" src="book_thing.jpg"></p>
<p>Thoughts at the thing:</p>
<ul>
<li>Books can seem so major, so heavy, so important... but most of them
   are ephemeral.</li>
<li>Nearly all book-reading is for entertainment.</li>
<li>Many things that we own, we don't really need to own.</li>
<li>Operations don't need to be complicated: The book thing doesn't
   track each book, doesn't cycle them or worry about staleness; you
   don't have to sign up to volunteer, you just show up. Their
   "processes" are dead simple, and it works.</li>
</ul>    
    ]]></description>
<link>http://planspace.org/20190602-book_thing_of_baltimore/</link>
<guid>http://planspace.org/20190602-book_thing_of_baltimore/</guid>
<pubDate>Sun, 02 Jun 2019 12:00:00 -0500</pubDate>
</item>
<item>
<title>Null impact of letters to very unlikely voters</title>
<description><![CDATA[

<p>Before the November 2018 election, I sent 2,181 personalized letters to very unlikely voters registered in New York's state senate district 5, encouraging them to vote. I sent 1,180 "birthday letters" in the months before the election, and 1,001 more conventional letters shortly before the election. Unfortunately, I didn't meaningfully increase voting rates in either group compared to control. This null result supports the conventional wisdom that extremely low-propensity voters are not optimal targets for get-out-the-vote efforts.</p>
<pre><code>| Group           | Total | Voted | % Voted |
|-----------------|-------|-------|---------|
| Control         | 3,135 | 349   | 11.13%  |
| Birthday letter | 1,180 | 140   | 11.86%  |
| Timely letter   | 1,001 | 111   | 11.09%  |</code></pre>

<p><strong>Statistical analysis</strong>: These results are not distinguishable. By t-test, p-values are 0.25 at best. The treatments are very similar, but one "effect" is positive and the other negative.</p>
<p><strong>Group selection</strong>: Using a 2018-07-20 voter file for NY SD5, I selected active registered Democrats who had voted at least once but not voted in the last five years. Back-testing showed equivalent groups had historically voted at low rates in midterm elections: 9%, 8%, and 4% in 2006, 2010, and 2014, respectively.</p>
<p><strong>Rationale</strong>: I hoped that by communicating with more people who wouldn't otherwise vote, more could be swayed. I was aware of the common practice of targeting people judged to be around 50% likely to vote, but I hoped to find a novel result, and thought that especially in the particularly high-saliency 2018 midterm, my approach could work.</p>
<p><strong>Birthday letter</strong>: To encourage engagement, I thought it would be fun to send birthday letters. This experiment group was the subset of the larger group with birthdays from August 19 to November 6. The letters had brief birthday greetings before the pro-voting message, and a "happy birthday" sticker on the outside of the hand-addressed envelopes. Letters were mailed a week before each birthday.</p>
<p><strong>Timely letter</strong>: These letters were nearly identical to birthday letters, but with generic greetings and no stickers. They were mailed a week before the election. This group was a random selection from the larger group not selected for birthday letters. (The remainder became the control group, not receiving any letter.) Research suggests timely messaging should be <em>more</em> effective, making the outcome of this treatment even more discouraging.</p>
<p><strong>Deliverability</strong>: I got 8% of letters bounced back to my address, which I hope is high for this kind of campaign. Of bounces, 6% voted. (I wouldn't read much into this.)</p>
<p><strong>Direct response</strong>: Letters included my personal mailing and email addresses. I had hoped to make a person-to-person connection with voters. I heard back from three people:</p>
<ul>
<li>One person was an active voter who had moved, but family at his
   previous address got the letter to him. He emailed and was very
   supportive.</li>
<li>One person found me on Twitter and was briefly curious about the
   project.</li>
<li>The mother of a letter's intended recipient emailed to say she was
   pro-voting but upset that I had the address and birthday of her
   daughter.</li>
</ul>
<p><strong>Results data</strong>: I used a 2019-02-28 voter file for NY SD5. Voters were re-identified by New York State Board of Elections voter ID.</p>
<p><strong>Conclusions</strong>: I wouldn't do this again. It was a learning experience, and it made me feel like I was doing something at the time. The overall change in turnout from 2014 to 2018 was dramatically greater than any effect ever achieved by a postal get-out-the-vote effort, which makes me think other influences are important.</p>    
    ]]></description>
<link>http://planspace.org/20190531-null_impact_of_letters_to_very_unlikely_voters/</link>
<guid>http://planspace.org/20190531-null_impact_of_letters_to_very_unlikely_voters/</guid>
<pubDate>Fri, 31 May 2019 12:00:00 -0500</pubDate>
</item>
<item>
<title>Understanding MyinTuition</title>
<description><![CDATA[

<p><a href="https://myintuition.org/">MyinTuition</a> is a simple online college
cost estimator for about 50 schools. I was curious about how it
worked, so I figured it out. I suspect they don't want me to say, and
I like them, so I won't. But here are some of my opinions and
experiences.</p>
<p>The rhetoric around MyinTuition is all about transparency, as in the
creator's 2014 paper about it, <a href="https://www.brookings.edu/wp-content/uploads/2016/06/12_transparency_in_college_costs_levine.pdf)">Transparency in College Costs</a>.
They want to be transparent about this message:
<a href="https://www.nytimes.com/interactive/2018/06/05/opinion/columnists/what-college-really-costs.html">Top Colleges Are Cheaper Than You Think (Unless You&#8217;re Rich)</a>.</p>
<p>College affordability is important. An expanded idea of transparency
might further include how the MyinTuition calculations are done, and
how the different schools vary. That's what I was curious about.</p>
<p>I originally thought I'd try to use machine learning to understand how
MyinTuition works, which would mean first collecting training data.
I'm not sure this was ever a good idea. For one thing, it doesn't seem
practical if data collection is severely rate-limited.</p>
<p>I explored on and off for a couple months. It was fun! It wouldn't be
as much fun to do now, what with the <a href="https://www.google.com/recaptcha/">CAPTCHA</a>s they've put
in. And unfortunately it may no longer be possible to access
MyinTuition at all using the IP addresses I was on at the time.</p>
<p>Figuring out the MyinTuition calculations and parameters for different
schools was interesting. I'll just recommend that you try a bunch of
schools and see what you get. You can find the calculators for all
participating schools <a href="https://myintuition.org/quick-college-cost-estimator/">on their site</a>.</p>
<p>Never stop learning, kids!</p>
<!-- https://bitbucket.org/ajschumacher/college_cost/ -->    
    ]]></description>
<link>http://planspace.org/20190529-understanding_myintuition/</link>
<guid>http://planspace.org/20190529-understanding_myintuition/</guid>
<pubDate>Wed, 29 May 2019 12:00:00 -0500</pubDate>
</item>
<item>
<title>The One Thing</title>
<description><![CDATA[

<p>This book is not all bad. A copy found its way from an airport
bookstore to a <a href="https://littlefreelibrary.org/">little free library</a>
to me, and I read it. Key points:</p>
<ul>
<li>Do the most important thing(s).</li>
<li>Make time to do things, blocking four-hour AM calendar "meetings"
   if need be.</li>
</ul>
<p>There's some other stuff in there about thinking big, identifying the proximal task, staying healthy, trying to not be a workaholic, etc. The book repeats pop science hits like <a href="https://en.wikipedia.org/wiki/Stanford_marshmallow_experiment">the marshmallow experiment</a> unquestioningly and without more recent <a href="https://www.theatlantic.com/family/archive/2018/06/marshmallow-test/561779/">updates</a>. There are ample cute turns of phrase that seem designed to play well in motivational speaking. It's not a great book, but it's quick to read, and it does sort of pump you up.</p>
<p>I think the core idea is not so bad. Two important aspects:</p>
<ul>
<li><strong>Just <em>completing</em> anything.</strong> There are so many distractions and
   ways to waste time, it's possible to "work" a lot and not actually
   get things done. It's helpful to identify a thing to do and then
   focus on completing it. The book mentions the inefficiency of
   multitasking, which rings true to me.</li>
<li><strong>Doing the <em>right</em> thing.</strong> There are many paths to not
   accomplishing anything. You can work on a problem for a long time,
   even get a lot of things done, without actually making real
   progress. You might end up with everything to show for your work
   except what you actually needed.</li>
</ul>
<p><img alt="The One Thing (cover)" src="the_one_thing_cover.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20190403-the_one_thing/</link>
<guid>http://planspace.org/20190403-the_one_thing/</guid>
<pubDate>Wed, 03 Apr 2019 12:00:00 -0500</pubDate>
</item>
<item>
<title>Swimming with Sharks, by Joris Luyendijk</title>
<description><![CDATA[

<p>"Inside the world of the bankers,"</p>
<blockquote>
<p>"You see a cluster of islands in the fog, staffed by mercenaries."
(page 145)</p>
</blockquote>
<p><a href="https://twitter.com/JORISLUIJENDIJK">Luyendijk</a> wrote
<a href="https://www.theguardian.com/commentisfree/joris-luyendijk-banking-blog">a 2011-2013 banking blog</a>
for the Guardian based on interviews with bankers in London. It became
this 2015 book. It's quite late to the "What happened in 2008?"
party, and even makes the observation that</p>
<blockquote>
<p>"the sector has become immune to exposure." (page 252)</p>
</blockquote>
<p>It does seem like some things these days are so bad they can hardly be
made to look worse, and yet far from being stopped, some people really
like them.</p>
<p>So Luyendijk writes about how things in finance are complicated, and
bad, but it's hard to single out any bad guys by name. His Dutch
perspective is interesting: he identifies lack of job security as a
major cause of problems in finance, for example.</p>
<p>On page 254 he has one paragraph of recommendations for law to change
the system:</p>
<ol>
<li>Break up banks so nothing is too big or too complex to fail</li>
<li>Don't let units of the same company have conflicts of interest
    with one another</li>
<li>Don't allow the building/selling/owning of overly complex
    financial products</li>
<li>Only allow bonuses that have symmetric risk</li>
</ol>
<p>No problem, right?</p>
<p>The observation and recommendation that resonated the most for me was
reconnecting reward to risk. With big public companies, a trader has
essentially only upside: good performance means a big bonus, but bad
performance means at worst finding another high-paying job at a
different company.</p>
<blockquote>
<p>"nobody should have more reason to lie awake at night worrying over
the risks to the bank's capital or reputation than the bankers
taking those risks." (page 254)</p>
</blockquote>
<p>I can get behind the sentiment, at least.</p>
<p><img alt="Swimming with Sharks cover" src="sharks_cover.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20190204-swimming_with_sharks/</link>
<guid>http://planspace.org/20190204-swimming_with_sharks/</guid>
<pubDate>Mon, 04 Feb 2019 12:00:00 -0500</pubDate>
</item>
<item>
<title>The Unreal and The Real, Volume Two</title>
<description><![CDATA[

<p>I bought
<a href="https://smile.amazon.com/Unreal-Real-Selected-Stories-Outer/dp/1618730355/">this</a>
collection of
<a href="https://en.wikipedia.org/wiki/Ursula_K._Le_Guin">Le Guin</a>'s short
stories and then she died before I read it. Before that, I once bought
a Kurt Vonnegut print and he died before it was delivered. I'm cursed!</p>
<p>I got the book because it has The Ones Who Walk Away From Omelas,
which I heard about in
<a href="https://www.amazon.com/How-Think-Survival-Guide-World/dp/0451499603">How to Think</a>
(which by the way is better for reacting to than learning from, if
there's a difference). Le Guin notes that Omelas "has had a long and
happy career of being used by teachers to upset students and make them
argue fiercely about morality." I missed that class, so it was nice to
catch up. File with:
<a href="https://en.wikipedia.org/wiki/Trolley_problem">trolley problems</a>?</p>
<p>To guess how Le Guin chose the stories for this volume, I'd say she
was trying to span the largest possible space of worlds. There are
lots of different universes. For example:</p>
<p>What if:</p>
<ul>
<li>the ratio of boy babies to girl babies was 1:16 instead of close to
   1:1?</li>
<li>one in a thousand people grew working, flying wings around age 20?</li>
<li>wolves were occasionally werepeople?</li>
<li>a peasant broke into Sleeping Beauty's castle and lived there while
   she slept?</li>
<li>an all-woman party of explorers reached the South Pole a couple
   years before
   <a href="https://en.wikipedia.org/wiki/Amundsen%27s_South_Pole_expedition">Amundsen</a>,
   but left no trace?</li>
</ul>
<p>Spoiler alert! A lot of the fun of many of these stories is figuring
out the premise, because the perspective doesn't always make it
obvious from the beginning.</p>
<p>In The Author of the Acacia Seeds, either people actually figure out
how to study the writing of ants and penguins and so on, or it's sort
of a joke about the modern academy inventing the study of everything,
whether there's really anything there to study or not.</p>
<p>My favorite story is probably Solitude.</p>
<p>Recommended reading order: As printed, but then re-read the
introduction.</p>
<p><img alt="cover of The Unreal and The Real, Volume Two" src="cover_volume_two.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20190129-unreal_and_the_real_volume_two/</link>
<guid>http://planspace.org/20190129-unreal_and_the_real_volume_two/</guid>
<pubDate>Tue, 29 Jan 2019 12:00:00 -0500</pubDate>
</item>
<item>
<title>Bird by Bird, by Anne Lamott</title>
<description><![CDATA[

<p><a href="https://smile.amazon.com/Bird-Some-Instructions-Writing-Life/dp/0385480016/">This</a>
is a charming short book containing "Some instructions on writing and
life."</p>
<p>It's very personal. Anne Lamott is cartoonishly neurotic and suggests
everyone else is too, which I've decided is nice.</p>
<p>She recommends index cards. I concur.</p>
<p>She mentions somehow that the population of the world is four billion.
I had to check the copyright date. It was 1994. Now in 2019 there are
7.7 billion people. Time flies!</p>
<p>Her writing glistens especially over short time scales. She is a
master of evocative two-item lists.</p>
<p>She has something to say (by proxy?) about not holding back:</p>
<blockquote>
<p>"Annie Dillard has said that day by day you have to give the work
before you all the best stuff you have, not saving up for later
projects. If you give freely, there will always be more."</p>
</blockquote>
<p>This is a phenomenon I've thought about in the context of breakdancing
competitions, and it is interesting to think about it also in writing,
and elsewhere.</p>
<p>Also she is very character-first. Plot comes from character, she says.</p>
<p><img alt="Bird by Bird (cover)" src="bird_by_bird_cover.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20190128-bird_by_bird_by_anne_lamott/</link>
<guid>http://planspace.org/20190128-bird_by_bird_by_anne_lamott/</guid>
<pubDate>Mon, 28 Jan 2019 12:00:00 -0500</pubDate>
</item>
<item>
<title>The Expectant Father and so on</title>
<description><![CDATA[

<p>I read some baby books in 2018. I got a copy of <a href="https://smile.amazon.com/Expectant-Father-Ultimate-Dads-Be/dp/0789212137/">The Expectant Father</a>, and then I got <a href="https://smile.amazon.com/New-Father-Dads-Guide-First/dp/0789211777/">The New Father</a>, by the same author. I also got the <a href="https://smile.amazon.com/FAQ-Expectant-Fathers-Armin-Brott/dp/0789212692/">FAQ</a> <a href="https://smile.amazon.com/FAQ-New-Fathers-Armin-Brott/dp/0789212706/">versions</a>, thinking (mostly wrongly) that it would be fun to see the material in multiple-choice-question form. And Erica read <a href="https://smile.amazon.com/What-Expect-When-Youre-Expecting/dp/0761187480/">What to Expect When You're Expecting</a>, so I saw bits of that as well.</p>
<p>I have mixed feelings on these baby books. Some things you can't prepare for. I think a lot of baby books are sold just to make people feel better. It's like reading about dancing: you might learn something, but you won't become a great dancer with books alone.</p>
<p>As far as facts, there are lots that you'll care about with some lowish probability. Baby books can be like encyclopedias that way. And for nearly everything, if you don't know in advance, you'll find out when you need to know. You can learn in advance about <a href="https://en.wikipedia.org/wiki/Meconium">meconium</a>, or later as needed, or not at all. Regardless, the baby poops.</p>
<p>For example, information about induction turned out to be relevant for our family. I don't recall reading much about induction, maybe because I didn't think it would be so relevant. As it happened, the best preparation I had came not from a book but from an in-person session we did at our hospital. Regardless, we relied on the medical professionals at the hospital, and I think it would have been a big mistake to favor an opinion from elsewhere over our nurses and doctors, who did a great job.</p>
<p>There is good general advice, but the parts most people agree on are pretty well known: don't smoke, eat healthy, etc. I think I prefer <a href="/20181209-brain_rules_for_baby/">Brain Rules for Baby</a> over more conventional baby books for summarizing such advice.</p>
<p>There are two things in particular that I would have liked to be more prepared for:</p>
<ul>
<li>During delivery, pushing changes at the last moment, when it's most painful, just as the baby's head is about to pop out. All of a sudden you're supposed to basically stop pushing so they can try to ease the head out without tearing anything. I don't recall hearing about this in advance. Maybe not everybody does it this way. We got these surprise directions in the middle of what was already a very intense process, and everything worked out reasonably well, but I feel like we wouldn't have minded learning about this in advance.</li>
<li>Babies cry sometimes for no apparent reason. Sometimes for considerable time (even if less than the pseudoscientific definitions associated with "colic"). I knew that babies cry, of course, but nothing prepared me for the feeling of my own daughter crying inconsolably in my arms. I don't know how much it would have helped, but I think I would have liked to hear more advice like, "Sometimes your baby will cry no matter what you do. It will be painful, but here are some things you can try. It will be okay."</li>
</ul>
<p>I'm new to all this. I'm trying to learn as much as I can. You can always learn some things from books, and there are always some things you can't. For having a child, I am strongly impressed with how valuable social learning and direct experience are when stacked against the information for sale in books.</p>
<p><img alt="cover of The Expectant Father" src="expectant_father_cover.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20181231-expectant_father/</link>
<guid>http://planspace.org/20181231-expectant_father/</guid>
<pubDate>Mon, 31 Dec 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>The Equation of a Plane</title>
<description><![CDATA[

<p>I wasn't a great undergraduate student, but I had at least one great
professor. She connected me with my post-graduate career path, and she
taught some of my calculus classes. One day she turned briefly from
the chalkboard and said with a smile:</p>
<blockquote>
<p>"If you don't know equation of a plane, I kill you!"</p>
</blockquote>
<p>I thought it was funny, and it wasn't what we were really working on
in class, so I didn't think much more about it. But because I never
thought it through then, doubt remained for some fifteen years: Was my
life in danger?</p>
<p>That teacher wasn't even an associate professor back then, by official
title. Recently, I learned that she's become an associate dean of the
college. I was inspired to finally think about the equation of a
plane.</p>
<p>Maybe she just meant that the equation of a plane is linear in
Cartesian coordinates. That could have been it. But I think she was
also getting at something about using the axis intercepts.</p>
<p>I learned \( y=mx+b \) like a kind of incantation, and I don't think
it was only because I went to Catholic schools. The "standard form" is
<a href="http://jwilson.coe.uga.edu/emt668/emat6680.2002/jackson/chapter%205%20lesson%20plan/day6.html">treated</a>
like a purposeless afterthought, more about following rules than
understanding anything.</p>
<p>But if the \( x \)-intercept is \( a \) and the \( y
\)-intercept is \( b \), then \( bx + ay = ab \) is a very nice
equation of a line. Maybe call it both-intercepts form.</p>
<p>Adding a \( z \)-intercept of \( c \), a plane then has a similar
equation: \( bcx + acy + abz = abc \).</p>
<p>I don't know for sure whether that's the equation that should have
spared my life back then, but it's a charming one. It's fun to think
about how it's related to other forms, and other dimensions&#8212;and how
silly a rule like "\( A \), \( B \), and \( C \) must be
integers" is.</p>
<p>I wish I had been a better student back then. I had no idea how useful
multivariate calculus and linear algebra would turn out to be, in
particular. But I've been very lucky, and I'm honored to have had
teachers who give me the pleasure of thinking things through, even
little things like this, and even many years later than I should have.
And I am deeply pleased to see that people who were so helpful to me
have themselves found greater success, and positions from which to
help many more people.</p>
<!-- mathjax for formulas -->

    ]]></description>
<link>http://planspace.org/20181228-the_equation_of_a_plane/</link>
<guid>http://planspace.org/20181228-the_equation_of_a_plane/</guid>
<pubDate>Fri, 28 Dec 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>The Whole-Brain Child</title>
<description><![CDATA[

<p>The advice of this book overlaps substantially with that in
<a href="/20181209-brain_rules_for_baby/">Brain Rules for Baby</a>. In
comparison, the science here feels less rigorous, but the advice still
seems reasonable. There's more focus on memory, which I mostly like.</p>
<blockquote>
<p>"... children whose parents talk with them about their experiences
tend to have better access to the memories of those experiences."
(page 8)</p>
</blockquote>
<p>If there's an overall theme, it is a kind of Western presentation of a
<a href="https://en.wikipedia.org/wiki/Middle_Way">middle way</a> between logic
and emotion, then between reactive thought and higher executive
function (shades of
<a href="/2011/12/17/selections-from-and-thoughts-on/">Thinking, Fast and Slow</a>).
There's a kind of meditative concept they call
<a href="https://www.drdansiegel.com/about/mindsight/">mindsight</a>.</p>
<p>The way they think about human development reminds me a little bit of
Montessori's "spontaneous discipline" - people become better.</p>
<blockquote>
<p>"As you create a whole-brain family, you also join a broader vision
of creating an entire society full of rich, relational communities
where emotional well-being is nurtured for this and future
generations." (page 148)</p>
</blockquote>
<p>Here are their "12 revolutionary strategies to nurture your child's
developing mind":</p>
<ol>
<li>Connect and redirect: Surfing emotional waves</li>
<li>Name it to tame it: Telling stories to calm big emotions</li>
<li>Engage, don't enrage: Appealing to the upstairs brain</li>
<li>Use it or lose it: Exercising the upstairs brain</li>
<li>Move it or lose it: Moving the body to avoid losing the mind</li>
<li>Use the remote of the mind: Replaying memories</li>
<li>Remember to remember: Making recollection a part of your family's daily life</li>
<li>Let the clouds of emotion roll by: Teaching that feelings come and go</li>
<li>SIFT (Sensations, Images, Feelings, Thoughts): Paying attention to what's going on inside</li>
<li>Exercise mindsight: Getting back to the hub</li>
<li>Increase the family fun factor: Making a point to enjoy each other</li>
<li>Connect through conflict: Teach kids to argue with a "we" in mind</li>
</ol>
<p>There's also a one-page (front and back) "refrigerator sheet" at the
back of the book, which is cute.</p>
<p><img alt="cover of The Whole-Brain Child" src="whole_brain_child_cover.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20181227-the_whole_brain_child/</link>
<guid>http://planspace.org/20181227-the_whole_brain_child/</guid>
<pubDate>Thu, 27 Dec 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>Gaussian Processes are Not So Fancy</title>
<description><![CDATA[

<p><a href="https://en.wikipedia.org/wiki/Gaussian_process">Gaussian Processes</a>
have a mystique related to the dense probabilistic terminology that's
already evident in their name. But Gaussian Processes are just models,
and they're much more like k-nearest neighbors and linear regression
than may at first be apparent.</p>
<p><img alt="Predictive mean and range" src="img/predictive_mean_and_range.png"></p>
<p>Gaussian Processes have
<a href="https://en.wikipedia.org/wiki/Kriging#Applications">applications</a>
ranging from finding gold to
<a href="https://cloud.google.com/blog/products/gcp/hyperparameter-tuning-cloud-machine-learning-engine-using-bayesian-optimization">optimizing hyperparameters</a>
of other models. The focus here is on how Gaussian Processes work,
using an example that's simple enough to show completely from
beginning to end.</p>
<hr>
<h3>A simple training data set</h3>
<p>A model is trained with predictors \( X \) and known labels \( y
\). Here's some data in Python:</p>
<pre><code class="language-python">train_X = [[0.8], [1.2], [3.8], [4.2]]
train_y = [   3,     4,    -2,    -2 ]</code></pre>

<p>Since elements of \( X \) are one-dimensional, all the data can be
shown in a simple figure:</p>
<p><img alt="Training data" src="img/training_data.png"></p>
<p>The task of a model is to predict \( y \) values for test points \(
x \).</p>
<hr>
<h3>Applying a kernel function</h3>
<p>Like <a href="https://en.wikipedia.org/wiki/Support_vector_machine">SVMs</a>,
Gaussian Processes use kernel functions. A kernel gives a closeness,
or similarity, between two points. This is related to distances, and a
kernel may involve distance. Here's the matrix of Euclidean distances
between points in our training data \( X \):</p>
<pre><code class="language-python">dist_XX = sklearn.metrics.pairwise_distances(train_X)
## array([[0. , 0.4, 3. , 3.4],
##        [0.4, 0. , 2.6, 3. ],
##        [3. , 2.6, 0. , 0.4],
##        [3.4, 3. , 0.4, 0. ]])
# Recall:
# train_X = [[0.8], [1.2], [3.8], [4.2]]</code></pre>

<p>The Gaussian radial basis function (RBF) kernel is commonly used. In
<a href="http://gaussianprocess.org/gpml/chapters/">Gaussian Processes for Machine Learning</a>,
Rasmussen and Williams call it the <em>squared exponential</em> kernel,
probably to avoid confusion with other things that are Gaussian. For
distance \( d \), it's \( e^{-\frac{1}{2}d^2}\):</p>
<pre><code class="language-python">def squared_exponential(distance):
    return np.exp(distance**2 / -2)</code></pre>

<p>It's one when distance is zero, and it goes to zero when distance is
big. This is evident for our data when we make the matrix of kernel
values for the training data \( X \):</p>
<pre><code class="language-python">kern_XX = squared_exponential(dist_XX)
## array([[1.  , 0.92, 0.01, 0.  ],
##        [0.92, 1.  , 0.03, 0.01],
##        [0.01, 0.03, 1.  , 0.92],
##        [0.  , 0.01, 0.92, 1.  ]])
# Recall:
# train_X = [[0.8], [1.2], [3.8], [4.2]]</code></pre>

<p>This matrix \( K(X, X) \) is a core component of Gaussian Processes,
and as the example shows, it reflects a core concern with nearness as
represented via a kernel function.</p>
<hr>
<h3>Using the Gaussian Process prediction equation</h3>
<p>This is Rasmussen and Williams' Equation 2.19 for the predictive
posterior distribution, which I promise isn't as bad as it looks:</p>
<p>\[ \mathbf{f_{\ast}} | X_{\ast}, X, \mathbf{f} \sim \mathcal{N}( K(X_{\ast}, X) K(X,X)^{-1} \mathbf{f}, \\ K(X_{\ast}, X_{\ast}) - K(X_{\ast}, X) K(X,X)^{-1} K(X, X_{\ast}) ) \]</p>
<p>Here \( \mathbf{f_{\ast}} \) is the predicted \( y \) for a test
point in \( X_{\ast} \) based on the training data \( X \) and \(
y \) labels \( \mathbf{f} \). It's predicted to be normally
distributed with mean \( K(X_{\ast}, X) K(X,X)^{-1} \mathbf{f} \)
and the given covariance. The mean can be considered "the" prediction,
though you can also sample.</p>
<hr>
<h3>Behaves like nearest neighbors</h3>
<p>Let's use Equation 2.19 to make a prediction for this \( X_{\ast} \):</p>
<pre><code class="language-python">test_X = [[1]]</code></pre>

<p>We find the kernel similarities between the test point and each point
of training data:</p>
<pre><code class="language-python">kern_xX = squared_exponential(
              sklearn.metrics.pairwise_distances(test_X, train_X))
## array([[0.98019867, 0.98019867, 0.01984109, 0.00597602]])</code></pre>

<p>The test point is close to the first two training points, and far from
the second two.</p>
<p>Let's evaluate just the first two terms of the predictive mean given
in Equation 2.19:</p>
<pre><code class="language-python">kern_xX.dot(np.linalg.inv(kern_XX))
## array([[ 0.50835358,  0.51127124, -0.01378216,  0.01144869]])</code></pre>

<p>It isn't exactly, but this looks a lot like a weighting for a weighted
average. And the prediction roughly fits that interpretation:</p>
<pre><code class="language-python">test_y = kern_xX.dot(np.linalg.inv(kern_XX)).dot(train_y)[0]
## 3.57</code></pre>

<p><img alt="Predictive mean at one point" src="img/predictive_mean_at_one_point.png"></p>
<p>This behavior is similar to k-nearest neighbors. Nearby points matter;
points that are far away don't. Nearest neighbors can even include a
weighting based on a kernel function.</p>
<p>Also like k-nearest neighbors, you have to use the whole training set
for every Gaussian Process prediction, comparing the test point to
every training point.</p>
<p>With Gaussian Processes, however, you don't have to specify a number
of neighbors \( k \). Every point that is near enough contributes to
the prediction.</p>
<p>The comparison here to a kind of weighted average nearest neighbors is
much more directly valid for
<a href="https://en.wikipedia.org/wiki/Kernel_regression">kernel regression</a>,
which is another technique that also uses kernels. With Gaussian
Processes, there's really a further step of curve-fitting going on.</p>
<hr>
<h3>It's linear regression</h3>
<p>The mean prediction of a Gaussian Process is the same as a linear
regression with a particular choice of coordinates. Let's talk about
how.</p>
<p>Why is \( K(X,X)^{-1} \) involved in the predictive mean?</p>
<p>Consider the kernel matrix as a transformation of the original
training data \( X \) into new variables, where each of the new
variables is kernel-nearness to one of the points of training data.
This is very much like transforming raw data to include interactions
or polynomial terms, as is common in regression. Say the transformed
data is \( Z \).</p>
<p>Linear regression coefficients
<a href="https://en.wikipedia.org/wiki/Ordinary_least_squares#Matrix/vector_formulation">can be solved for</a>
with \( (Z^T Z)^{-1} Z^T \). But with a nice symmetric square matrix
like \( K(X,X) \), this is the same as just taking \( Z^{-1} \)
directly.</p>
<p>So the mean prediction of a Gaussian Process is the same as linear
regression in the coordinates defined by kernel similarities with each
training point. It <em>is</em> linear regression.</p>
<hr>
<h3>With covariance</h3>
<p>With Gaussian Processes, kernel functions are also called covariance
functions. Things that are kernel-near vary together&#8212;they have similar
values&#8212;and this enforces smoothness.</p>
<p>Here's the covariance part of Equation 2.19 again. It has two terms:</p>
<p>\[ K(X_{\ast}, X_{\ast}) - K(X_{\ast}, X) K(X,X)^{-1} K(X, X_{\ast}) \]</p>
<p>The positive first term shows that test point(s) vary together when
they're close to one another. The negative second term (which is also
a linear regression solution, like the mean) captures how much
variance is eliminated due to being close to observed points.</p>
<!-- How to read the negative term as linear regression: The data set
X is, for each training point, kernel nearness to each other training
point. The training labels y are kernel nearness from test data to
training data. Then the test point has its nearness to the training
data, and we get out a consolidated estimate of nearness of this test
point to the training data. It can be thought of like a local weighted
average, just like for the mean. -->

<hr>
<h3>Predicting for multiple points</h3>
<p>If you get the predictive mean for many points, you can draw out a
curve:</p>
<p><img alt="Predictive mean at many points" src="img/predictive_mean_at_many_points.png"></p>
<p>You may instead want to use the predictive mean and variance at some
test point to <em>sample</em> an outcome \( y \). If you then take that
sampled value as a new point of training data (adding it to your
training set) future predictions will be consistent with that first
one, and so on.</p>
<p>You can equivalently make multiple consistent predictions
simultaneously by putting multiple test points in \( X_{\ast} \) and
sampling from a multivariate Gaussian.</p>
<p>Just like the mean alone, values sampled this way will draw out a
smooth curve. But unlike the mean alone, each random draw will be a
different curve: Gaussian Processes are random over a space of
functions. An approachable
<a href="http://katbailey.github.io/post/gaussian-processes-for-dummies/">post by Bailey</a>
focuses on this.</p>
<p>It can be fun to sample curves, but often the mean and variance alone
are useful.</p>
<p><img alt="Predictive mean and range" src="img/predictive_mean_and_range.png"></p>
<hr>
<h3>The Bayesian prior away from data</h3>
<p>Gaussian Processes have Bayesian priors. For the example here, the
assumption is that the function is always zero with covariance one,
until we see training data showing otherwise.</p>
<p>In Equation 2.19, you can think of the mean as zero plus contributions
from the training data; that's where the zero comes from. Covariance
comes from the kernel function, which gets as big as one. To change
the prior on the covariance, change the kernel function.</p>
<p><img alt="Predictive mean and range (wider view)" src="img/predictive_mean_and_range_wider_view.png"></p>
<p>The prior is visible when the bounds of the plot are expanded, which
illustrates that Gaussian Processes often focus on local interpolation
more than extrapolation.</p>
<hr>
<h3>Length scale matters</h3>
<p>The kernel specifies the scale of the variance, and in the case of the
squared exponential kernel, there's also a length scale parameter that
has significant effects.</p>
<pre><code class="language-python">def squared_exponential(distance, length_scale=1):
    return np.exp((distance / length_scale)**2 / -2)</code></pre>

<p>For our example, a length scale of one works reasonably well. For a
smaller length scale, the function is allowed to change faster, and
the prior asserts itself more quickly:</p>
<p><img alt="Predictive mean with length scale = 0.05" src="img/predictive_mean_with_small_length_scale.png"></p>
<p>For a Gaussian Process to capture a trend, its kernel needs to support
it. In the case of the squared exponential kernel, this means a long
enough length scale.</p>
<hr>
<h3>When hyperparameters are your parameters</h3>
<p>As presented here, a Gaussian Process will always exactly fit its
training data. This is often considered a sign of overfitting, and
regardless it's clearly unsustainable if training data ever has two
different \( y \) values for identical \( x \) values.</p>
<p>Noise can be added to address these issues, and the scale of the noise
is another hyperparameter, joining the overall scale and length scale
of the covariance function.</p>
<p>To get really interesting behavior may require composing kernel
functions, altering what "near" means for the model and adding even
more hyperparameters, as in
<a href="https://scikit-learn.org/stable/modules/gaussian_process.html#gpr-on-mauna-loa-co2-data">this example</a>.</p>
<p>Gaussian Process implementations like
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html">sci-kit's</a>
try to automatically fit these hyperparameters, which may remove some
of the need to know what they should be in advance. But optimization
can't do all the work of designing an appropriate kernel for a
problem, or eliminate the difficulty of distances in high-dimensional
spaces.</p>
<p>There are also some approaches for improving computational efficiency.</p>
<hr>
<h3>Not useless, but not magical</h3>
<p>Even with enhancements, the fundamental nature of Gaussian Processes
is as presented here: local smooth curve fitting built on linear
regression.</p>
<p>A Gaussian Process might be useful for you. But please don't assume
that it is sophisticated just because the language around it often is,
or that its results are automatically true just because they have
error bars.</p>
<hr>
<p>The code and plots from this post are all in
<a href="https://github.com/ajschumacher/ajschumacher.github.io/blob/master/20181226-gaussian_processes_are_not_so_fancy/gaussian_processes.ipynb">a Jupyter notebook</a>.</p>
<p>Thanks to Erica Blom, Marco Pariguana, Sylvia Blom, Travis Hoppe, and Ajay Deonarine for reading drafts of this post and providing feedback. Thanks also to everybody <a href="https://www.reddit.com/r/MachineLearning/comments/ac6er3/d_gaussian_processes_are_not_so_fancy/">on Reddit</a>, <a href="https://news.ycombinator.com/item?id=18814776">on HN</a>, <a href="https://www.datatau.com/item?id=28391">on DataTau</a>, <a href="https://twitter.com/search?f=tweets&amp;vertical=default&amp;q=https%3A%2F%2Fplanspace.org%2F20181226-gaussian_processes_are_not_so_fancy%2F&amp;src=typd">on Twitter</a>, <a href="https://pinboard.in/url:077f95c750f2b064e882bafb0d7899b7a3eaf48a/">on Pinboard</a>, and elsewhere!</p>
<!-- mathjax for formulas -->

    ]]></description>
<link>http://planspace.org/20181226-gaussian_processes_are_not_so_fancy/</link>
<guid>http://planspace.org/20181226-gaussian_processes_are_not_so_fancy/</guid>
<pubDate>Wed, 26 Dec 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>Brain Rules for Baby</title>
<description><![CDATA[

<p>To be a good parent, be a good person. The core recommendations on "How to raise a smart and happy child from zero to five" are empathy and understanding emotion.</p>
<blockquote>
<p>"Human learning ... is primarily a relational exercise." (page 111)</p>
</blockquote>
<p>Medina aims for objective reasonableness, and it's usually easy for me to agree.</p>
<p>For the abbreviated book (and a few extra nuggets) check out the 15 pages of "practical tips" starting on page 287. Here's my summary of recommendations:</p>
<p>When someone is in an emotional state, use "the empathy reflex" (page 83):</p>
<ol>
<li>Describe the emotional changes you think you see.</li>
<li>Make a guess as to where those emotional changes come from.</li>
</ol>
<p>This is like a flip of "<a href="https://en.wikipedia.org/wiki/I-message">I statements</a>."</p>
<p>After empathy, the second major focus is on understanding emotion: talking about emotions, accepting them as natural, and (eventually) not being ruled by them.</p>
<p>There are lots of concrete recommendations:</p>
<ul>
<li>(During pregnancy) Gain appropriate weight, eat a balanced diet, exercise moderately, reduce stress.</li>
<li>Breast-feed for a year.</li>
<li>Talk to your baby a lot.</li>
<li>Praise effort, not IQ (encourage a growth mindset).</li>
<li>Use "authoritative parenting" which is "demanding and warm" and involves:<ul>
<li>Clear, consistent rules and rewards</li>
<li>Swift punishment</li>
<li>Rules that are explained</li>
</ul>
</li>
<li>(Your child should) Watch no TV before age two.</li>
<li>(Your child should) Exercise frequently.</li>
<li>(Your child should) Play a lot in open-ended ways, such as the "mature dramatic play" of <a href="https://toolsofthemind.org/">Tools of the Mind</a>, which may involve making a "play plan."</li>
<li>(Your child should) Learn sign language.</li>
<li>(Your child should) Study a musical instrument for ten years.</li>
</ul>
<p>Medina gives a very reasonable presentation of intelligence and IQ, including this historical tidbit on how we got the term "Intelligence Quotient" in the first place:</p>
<blockquote>
<p>"The score was the ratio of a child's mental age to his or her chronological age, multiplied by 100. So a 10-year-old who could solve problems normally solved only by 15-year-olds had an IQ of 150: (15/10) X 100." (page 95)</p>
</blockquote>
<p>On page 100 we get five ingredients of human intelligence stew, which I like:</p>
<ul>
<li>The desire to explore</li>
<li>Self-control</li>
<li>Creativity</li>
<li>Verbal communication</li>
<li>Interpreting nonverbal communication</li>
</ul>
<p>The associating, questioning, observing, experimenting, and networking from an old Harvard Business Review article on "<a href="https://hbr.org/2009/12/the-innovators-dna">Innovators DNA</a>" get woven in, and it's not awful.</p>
<p>Three last details I enjoyed:</p>
<ul>
<li>Episodic memory is a distinct kind of memory, and may be particularly useful for creative thinking. (page 106) Maybe consciously draw on it when brainstorming?</li>
<li>There's a test of creativity called the <a href="https://en.wikipedia.org/wiki/Torrance_Tests_of_Creative_Thinking">Torrance Tests of Creative Thinking</a>. (page 107) It's mostly things like "how many uses can you come up with for X?"</li>
<li>There's a Harvard-developed test of morality, now at <a href="http://www.moralsensetest.com/">moralsensetest.com</a>. (page 222) It's mostly variations on <a href="https://en.wikipedia.org/wiki/Trolley_problem">the trolley problem</a>.</li>
</ul>
<p><img alt="Brain Rules for Baby cover" src="cover.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20181209-brain_rules_for_baby/</link>
<guid>http://planspace.org/20181209-brain_rules_for_baby/</guid>
<pubDate>Sun, 09 Dec 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>Is it worth doing even if it fails?</title>
<description><![CDATA[

<p>Many things can "succeed" or "fail." Avoid anything that isn't worth
doing even if it fails.</p>
<p>If two tasks each have a probability of success and payout, but one is
worth doing regardless of success and one is only about payout, it
almost doesn't matter what the probabilities and payouts are. One
guarantees a good use of time.</p>
<p>This filter also averts unhealthy fixation on "winning" and excessive
disappointment with "losing." It lets you focus on the task itself,
which is the right focus.</p>
<p>You can't always choose what you have to do. But you can try to find
or create value even in endeavors you wouldn't otherwise choose.</p>
<p>Asking "Is it worth doing even if it fails?" encourages healthy things
like sports, discourages antisocial things like fraud, and provides a
positive direction to move everything in between. I think it's a
useful question.</p>    
    ]]></description>
<link>http://planspace.org/20181204-worth_doing_even_if_it_fails/</link>
<guid>http://planspace.org/20181204-worth_doing_even_if_it_fails/</guid>
<pubDate>Tue, 04 Dec 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>How To Invent Everything</title>
<description><![CDATA[

<p><a href="http://www.howtoinventeverything.com/">How To Invent Everything</a> is like <a href="https://www.billnye.com/">Bill Nye</a> writing how-tos for <a href="https://www.youtube.com/channel/UCAL3JXZSzSm8AlZyD3nQdBA">Primitive Technology</a>, in the distinctive voice of <a href="https://www.qwantz.com/">Dinosaur Comics</a> writer and actual author <a href="https://en.wikipedia.org/wiki/Ryan_North">Ryan North</a>. It's fun!</p>
<blockquote>
<p>"Scientists are often seen as turbonerds, but the philosophical foundations of science are actually those of pure punk-rock anarchy: never respect authority, never take anyone's word on anything, and test all the things you <em>think</em> you know to confirm or deny them for yourself." (page 34)</p>
</blockquote>
<p>The book is a compendium of "<a href="http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html">You</a> <a href="http://www.ams.org/notices/200601/fea-chow.pdf">could</a> <a href="https://reprog.wordpress.com/2010/05/13/you-could-have-invented-git-and-maybe-you-already-have/">have</a> <a href="http://luis.impa.br/aulas/lectures/inventingTopology.pdf">invented</a>" <a href="http://blog.ezyang.com/2012/02/anatomy-of-you-could-have-invented/">articles</a> for everything from language to selective breeding to steel to the <a href="https://en.wikipedia.org/wiki/Pelton_wheel">pelton wheel</a> to computers. A lot of fun (and some dangerous) science fair projects could be adopted from these pages. Do you know how to make your own charcoal? Or that clover is a <a href="https://en.wikipedia.org/wiki/Legume">legume</a> useful in crop rotation? This book is chockablock with <a href="https://minecraft.gamepedia.com/Recipe">Minecraft recipes</a> for the real world.</p>
<p>The "survival guide for the stranded time traveler" framing is amusing, but it's historical details (like the story of the <a href="https://en.wikipedia.org/wiki/Semmelweis_reflex">Semmelweis reflex</a>) that really add interest. There are a few <a href="http://www.howtoinventeverything.com/errata">errata</a> but overall this is the most easily recommendable book I've read in some time.</p>
<p><img alt="How To Invent Everything cover" src="cover.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20181125-how_to_invent_everything/</link>
<guid>http://planspace.org/20181125-how_to_invent_everything/</guid>
<pubDate>Sun, 25 Nov 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>Machine learning / Deep learning</title>
<description><![CDATA[

<p>I participated in a
<a href="https://www.meetup.com/TechinMotionDC/events/252910659/">panel</a> on
deep learning yesterday, so I thought about some of the introductory
questions and wrote out my responses.</p>
<hr>
<h3>How would you define machine learning?</h3>
<p>Machine learning is programming with examples instead of instructions.</p>
<p>It's a way to get computers to do something: in that sense it's
"programming." It's been called
<a href="https://medium.com/@karpathy/software-2-0-a64152b37c35">Software 2.0</a>.</p>
<p>Usually we program by writing explicit instructions, step by step.
With machine learning, we program using examples, by which I mean
data.</p>
<p>Say that programming is writing functions, which is basically right. A
function takes some input and returns some output.</p>
<p><a href="https://en.wikipedia.org/wiki/Higher-order_programming">Higher-order programming</a>
involves functions as the inputs and outputs of other functions, and
machine learning is a specific kind of higher-order programming.</p>
<p>Machine learning is done by a function that takes data (examples) as
input and produces a function as output. Running that higher-order
function is when machine learning takes place. We say that we learn a
function.</p>
<p>Sometimes learned functions are called models, and learning them is
sometimes called training or fitting.</p>
<p>There can also be functions that learn functions that learn functions,
as in <a href="https://arxiv.org/abs/1611.01578">Neural Architecture Search</a>,
which involves machine learning at multiple levels.</p>
<h3>What is deep learning? What is the difference between deep learning and machine learning?</h3>
<p>Deep learning is machine learning where the function you're learning
has a particular style of implementation.</p>
<p>In deep learning, the learned function has an internal implementation
involving one or more intermediate representations.</p>
<p>Aspects of these intermediate stages are sometimes called layers or
activations.</p>
<p>The number of layers is how we measure the depth of the model.</p>
<p>I don't care to argue about how many layers you "need" to be "deep."
As far as I'm concerned if there's more than zero intermediate
representations, you can call it deep if you want to. But it's common
to have five, ten, twenty, or more layers.</p>
<p>Usually, but not always, when people talk about deep learning they're
also talking about neural nets, and usually using
<a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a>.</p>
<p>The reason people care about deep learning is that it performs better
than many machine learning alternatives on a lot of hard problems
typically involving high-dimensional inputs, like images, audio, and
text.</p>
<hr>
<p>Cassie Kozyrkov's <a href="https://www.youtube.com/watch?v=iLu9XyZ55oI">talk</a>
has a number of useful metaphors for machine learning in practice and
I found it helpful for thinking about how to explain things to a
general audience.</p>    
    ]]></description>
<link>http://planspace.org/20180823-machine_learning_deep_learning/</link>
<guid>http://planspace.org/20180823-machine_learning_deep_learning/</guid>
<pubDate>Thu, 23 Aug 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>Land of Lisp</title>
<description><![CDATA[

<p><a href="http://landoflisp.com/">Land of Lisp</a> is an irresistibly fun <a href="https://common-lisp.net/">Common Lisp</a> book. The cartoon illustrations and "Learn to program in Lisp, one game at a time" subtitle don't fully suggest the depth of the content. Recursion is in Chapter 2, you write both <a href="https://www.graphviz.org/">Graphviz</a> and raw <a href="https://en.wikipedia.org/wiki/Scalable_Vector_Graphics">SVG</a> for graphics, you code up a web server from scratch, and you write your own lazy evaluation and multiple <a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSL</a>s with macros before the end of the book. With that much material, some glitches sneak in, but it's still a very nice book.</p>
<p><img alt="Land of Lisp cover" src="land_of_lisp-cover.jpg"></p>
<p>I've done a little bit with <a href="https://en.wikipedia.org/wiki/Emacs_Lisp">Emacs Lisp</a> and <a href="https://clojure.org/">Clojure</a>, but this was my first time learning anything much about Common Lisp. Thinking about languages through contrast (<a href="https://planspace.org/20141129-ruby_symbols_are_not_lisp_symbols/">one old example of mine</a>) is fun, and there's a good deal of that in Land of Lisp.</p>
<p><img alt="Haskell/Lisp map" src="map.png"></p>
<p>I really liked some of the organization/presentation of material. The Periodic Table of the Loop Macro on pages 200 and 201 was one striking example.</p>
<p><img alt="Periodic Table of the Loop Macro" src="loop_table.png"></p>
<p>The way the author <a href="https://en.wikipedia.org/wiki/Memoization">memoized</a> functions, by first defining the un-memoized version and then defining the memoized version with the same name, capturing the original function by <a href="https://en.wikipedia.org/wiki/Closure_(computer_programming)">closure</a>, really tickled me.</p>
<p>There was also reference to a Haskel functional-style "<a href="http://happs.org/">database</a>" that I thought was interesting. Maybe sort of like <a href="https://www.datomic.com/">Datomic</a>? And there were occasional references to other neat things; I may now read <a href="https://cs.brown.edu/~sk/Publications/Papers/Published/khmgpf-impl-use-plt-web-server-journal/">Implementation and Use of the PLT Scheme Web Server</a>, for example.</p>
<p>I've thought about good ways to learn to program a little bit, even <a href="https://planspace.org/20150101-learn_to_code_with_emacs/">suggesting</a> that learning Emacs/Lisp might be good. Then at least you can use Emacs Lisp to customize your editor. I don't think I know of any current Common Lisp projects.</p>
<p>It's nice when learning (and working with) a language to have a handy documentation system. Emacs Lisp <a href="https://planspace.org/20141230-use_info_in_emacs/">has this</a> in spades. In Python, I think beginners should know about, for example, <code>help()</code> and <code>dir()</code> very early. There's nothing like this covered in Land of Lisp. The only documentation referenced, as I recall, was the <a href="http://www.lispworks.com/documentation/HyperSpec/Front/">Common Lisp HyperSpec</a>, which doesn't seem very beginner-friendly.</p>
<p>The most extremely anti-didactic bit of the book, however, has to be on page 382: "The only way to understand [these functions] is to stare at them for a long time." I think non-explanations like this are not likely to be helpful to anyone.</p>
<p>Then there are little glitches in the book. I suspect the book kept expanding and editors were overwhelmed:</p>
<ul>
<li>The intro to Chapter 7 claims to include things that don't start until Chapter 8.</li>
<li><code>sexp</code> is used in code but never <a href="https://en.wikipedia.org/wiki/S-expression">explained</a>, which I don't think is a good idea.</li>
<li><code>pushnew</code> is used on page 149 but not explained until page 368.</li>
<li>On page 445 it says "Restarts are discussed in Chapter 14," but they aren't.</li>
<li>On page 450 a reference to Chapter 16 should be to Chapter 17.</li>
</ul>
<p>In the end the book can't cover everything. For example, the <a href="https://en.wikipedia.org/wiki/Common_Lisp_Object_System">Common Lisp Object System</a> is praised but not explained in enough detail for me to know why it's so great. That was particularly frustrating because I'd still love to see more about managing large projects in languages like Common Lisp or Clojure (with OO concepts or not).</p>
<p>I liked the book a lot; it's great recreational reading for language breadth.</p>    
    ]]></description>
<link>http://planspace.org/20180812-land_of_lisp/</link>
<guid>http://planspace.org/20180812-land_of_lisp/</guid>
<pubDate>Sun, 12 Aug 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>The Broken Earth trilogy</title>
<description><![CDATA[

<p><a href="https://en.wikipedia.org/wiki/N._K._Jemisin">N. K. Jemisin</a>'s three-book tale is both enjoyable and sufficiently deep to support a lot of conversation. The first <a href="https://en.wikipedia.org/wiki/Hugo_Award">Hugo</a>-winning book, <a href="https://en.wikipedia.org/wiki/The_Fifth_Season_(novel)">The Fifth Season</a>, was the first book I read for a book club. I couldn't stop, and finished <a href="https://en.wikipedia.org/wiki/The_Obelisk_Gate">The Obelisk Gate</a> and <a href="https://en.wikipedia.org/wiki/The_Stone_Sky">The Stone Sky</a> as well.</p>
<p><img alt="Broken Earth covers" src="BrokenEarth.jpg"></p>
<p>Here some aspects of the trilogy that I found interesting:</p>
<ul>
<li>Revolution vs. gradual change or "working within the system": What
   is possible, and when is revolutionary change justified/necessary?</li>
<li>Science fiction vs. fantasy (possibly philosophy of science?):
   Arthur C. Clarke's "Any sufficiently advanced technology is
   indistinguishable from magic" is relevant, but also, what if some
   sufficiently advanced science turns out to be very different from
   what the current popular scientific view thinks is likely?</li>
<li>Gift vs. curse: Having special powers isn't always as great as in
   Harry Potter; this is a little more like X-Men, but more extreme.</li>
<li>Race and slavery: There's a lot to think about; one aspect is an
   R-word that maps pretty directly to the real-world N-word.</li>
</ul>
<p>I noted some quotes from each book, though I started saving more after
the first volume:</p>
<h3>The Fifth Season</h3>
<blockquote>
<p>"It's a gift if it makes us better. It's a curse if we let it
destroy us." (p. 418)</p>
</blockquote>
<h3>The Obelisk Gate</h3>
<blockquote>
<p>"He's never hurt you, though. The world has, but not him. Maybe the
world deserved to be destroyed." (p. 31)</p>
<p>"Something else, neither flesh nor stone. Something immaterial, and
yet it is there for you to perceive. It glimmers in threads strung
between the bits of him, crossing itself in lattices, shifting
constantly. A... tension? An energy, shining and streaming.
Potential. Intention." (p. 101)</p>
<p>"He showed you-again and again, unrelentingly, he would not let you
pretend otherwise-that if obedience did not make one feel safe from
the Guardians or the nodes or the lynchings or the breeding or the
disrespect, then what was the point? The game was too rigged to
bother playing." (p. 159)</p>
<p>"Like those weird cults that crop up from time to time. I heard of one that asks an old man in the sky to keep them alive every time they go to sleep. People need to believe there's more to the world than there is." (p. 166)</p>
<p>"It isn't fair. You just want your life to matter."</p>
</blockquote>
<h3>The Stone Sky</h3>
<blockquote>
<p>'When a slave rebels, it is nothing much to the people who read
about it later. Just thin words on thinner paper worn finer by the
friction of history. ("So you were slaves, so what?" they whisper.
Like it's nothing.)' (p. 7)</p>
<p>"People who are not tuners can perceive magic only in rudimentary
ways; they use machines and instruments to do what is natural for
us." (p. 107)</p>
<p>"But breathing doesn't always mean living, and maybe... maybe
genocide doesn't always leave bodies." (p. 179)</p>
<p>'"Because it must be his choice, first." Harder voice here. A
reprimand. You flinch. "More importantly, because we are fragile at
the beginning, like all new creatures. It takes centuries for us,
the who of us, to...cool. Even the slightest of pressures-like you,
demanding that he fit himself to your needs rather than his own-can
damage the final shape of his personality."' (p. 282)</p>
<p>'"Orogeny," I say, sharply so she will pay attention, "was never the
only way to change the world."' (p. 396)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20180723-broken_earth_trilogy/</link>
<guid>http://planspace.org/20180723-broken_earth_trilogy/</guid>
<pubDate>Mon, 23 Jul 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>Geolocation precision by digit</title>
<description><![CDATA[

<p>Latitude and longitude define increasingly fine grids over the Earth
as you add digits after the decimal points, but no matter how fine the
grid, most things still aren't at points of intersection. How far you
can get from a closest point of intersection as the grid gets finer is
a way to describe precision. This precision can be compared to
measurement accuracy and the sizes of objects of interest.</p>
<p>The Earth is not perfectly spherical, and the size of one degree can
vary, especially for longitude. To get an upper bound on error, we'll
use the circumference of the Earth at the equator, around 40,075 km,
to start calculations. With correct rounding, maximum error in one
direction is half a unit. That maximum error could happen in two
directions. Using the usual Pythagorean theorem on a plane for the
worst-case diagonal distance is easy and will be slightly higher than
the actual distance along the Earth's surface, assuming no change in
elevation, so the bound won't even be as tight as it could be. Also
I'll round up.</p>
<hr>
<h3>0.&#176; lat, 0.&#176; lon: 80 km</h3>
<p>Every point that rounds, to the nearest degree, to a particular
latitude and longitude, is within 80 kilometers of the exact
intersection of those lines of latitude and longitude.</p>
<h3>0.1&#176; lat, 0.1&#176; lon: 8 km</h3>
<p>With one decimal place, you're within 8 km. This might already be
precise enough to describe a large city.</p>
<h3>0&#176; 59' lat, 0&#176; 59' lon: 1.4 km</h3>
<p>Any point that is the same to the nearest minute in latitude and
longitude is within 1.4 km of that position exactly.</p>
<p>I recommend sticking with the decimal system.</p>
<h3>0.12&#176; lat, 0.12&#176; lon: 800 m</h3>
<p>Two decimal places of precision gets you within 800 meters.</p>
<h3>0.123&#176; lat, 0.123&#176; lon: 80 m</h3>
<p>Three decimal places will always be within 80 m of the point
described. This is specific enough already for the smallest towns and
even large buildings.</p>
<h3>0&#176; 59' 59" lat, 0&#176; 59&#176; 59" lon: 22 m</h3>
<p>When you have a location to the nearest second, it's within 22 m of
that exact location.</p>
<p>This is the annoying format that you get, for example, from the Apple
Compass app. If your phone's location accuracy
<a href="https://www.gps.gov/systems/gps/performance/accuracy/">is within 5 m</a>,
then you likely have your location correct to the nearest second,
though you may not. (Your phone reports more precise location values
internally, as you can see on your map.)</p>
<h3>0.1234&#176; lat, 0.1234&#176; lon: 8 m</h3>
<p>Four decimal places is enough to specify pretty much any landmark.</p>
<h3>0.12345&#176; lat, 0.12345&#176; lon: 80 cm</h3>
<p>You probably consider everything within your five-digit
latitude/longitude location your personal space. But also, at five
decimal places of precision, my best guess is that error in the
accuracy of your GPS is around the same size or greater than the error
from using this many digits.</p>
<h3>0.123456&#176; lat, 0.123456&#176; lon: 8 cm</h3>
<p>You don't need six digits of precision for the locations of buildings;
you need six digits of precision to describe where each plate is set
on the dinner table.</p>
<p>If you can measure your location as accurately as this, you have
specialized equipment and probably know more about these kinds of
error issues than I do.</p>
<h3>0.1234567&#176; lat, 0.1234567&#176; lon: &lt; 1 cm</h3>
<p>With seven digits of precision you can differentiate one marble from
the marble next to it.</p>
<h3>0.12345678&#176; lat, 0.12345678&#176; lon: &lt; 1 mm</h3>
<p>Is latitude and longitude really your best choice of coordinate
system?</p>
<hr>
<p>You can check out my calculations in <a href="latlon.ipynb">latlon.ipynb</a>.</p>    
    ]]></description>
<link>http://planspace.org/20180719-geolocation_precision_by_digit/</link>
<guid>http://planspace.org/20180719-geolocation_precision_by_digit/</guid>
<pubDate>Thu, 19 Jul 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>Portfolios of the Poor</title>
<description><![CDATA[

<blockquote>
<p>"One of the biggest challenges of living on two dollars a day is that it doesn't always come." (page 181)</p>
</blockquote>
<p><a href="http://www.portfoliosofthepoor.com/"><img alt="Portfolios of the Poor (cover)" src="cover.jpg"></a></p>
<blockquote>
<p>"Convenience, flexibility, and reliability are at the heart of building workable financial tools for the poor, and are key to understanding the economic lives of poor households more broadly. Just as we found no households truly living hand to mouth&#8211;even among the very poor&#8211;we found no households so absolutely limited in their resources that price was the overriding determinant of financial choices." (page 153)</p>
</blockquote>
<p><a href="http://www.portfoliosofthepoor.com/">Portfolios of the Poor</a> is a 2009 book referenced in <a href="/20180218-scarcity_by_sendhil_mullainathan_and_eldar_shafir/">Scarcity</a>. While <em>Scarcity</em> positions itself as explaining why poor people make bad financial decisions, <em>Portfolios</em> explores without judgment how people who are poor manage their money: <em>Portfolios</em> doesn't necessarily think a high-interest loan is "bad" if it helps someone solve a pressing problem.</p>
<p>The source data are <a href="http://financialdiaries.com/">financial diaries</a>, collected in a kind of ethnographic process in Bangladesh, India, and <a href="https://www.datafirst.uct.ac.za/dataportal/index.php/catalog/2">South Africa</a>. They follow around 250 families for a year or more each, collecting detailed information that frequently surfaces as personal anecdotes.</p>
<p>You can get a quick summary by reading Chapter Seven, where they present their recommendations (based on observations) in just eleven pages, with this structure:</p>
<ul>
<li>Opportunities: Cash-flow management, building savings, loans for all uses</li>
<li>Principles: Reliability, convenience, flexibility, structure</li>
</ul>
<p>Chapter One is a more complete overview of the book and its methods. Chapter two focuses on cash flow, and the "triple whammy" of low income, irregular income, and lack of really helpful financial instruments. Chapter three is on dealing with risk, chapter four is on building up usefully large sums of money, and chapter five is on the sometimes strange world of pricing financial instruments for the poor.</p>
<p>One interesting service involves having money collected and kept over time for a fee, which seems like a negative interest rate. But in a repeated setting, the difference between saving and borrowing can blur.</p>
<blockquote>
<p>"In Vijaywada, there are customers who simply didn't distinguish between deposit collectors and moneylenders, so similar is the service provided. Both offered repeated money-accumulation cycles for a fee." (page 151)</p>
</blockquote>
<p>The authors explore this and other cases in which the rich-world focus on interest rates may not be the most appropriate, as costs often behave more like fees. Interest is rarely compounded, for example (page 136), and terms are not always as strict as they may seem, though this doesn't necessarily benefit everyone in the same ways.</p>
<blockquote>
<p>"...repayment delays are factored into the nominal price, with the effect that the customer who repays on time pays the highest price. This inverted pattern of incentives can be seen as one of the more unsatisfactory aspects of informal loan finance." (page 141)</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Microfinance">Microfinance</a> is not the largest money-mover in the diaries, but the authors are interested in it, and in improving it. Especially in Bangladesh many diary households were working with microfinance providers like <a href="https://en.wikipedia.org/wiki/Grameen_Bank">Grameen Bank</a>. Author Stuart Rutherford founded <a href="http://www.safesave.org/">SafeSave</a> which is now part of <a href="https://en.wikipedia.org/wiki/BRAC_(organization)">BRAC</a>, and they also mention <a href="https://en.wikipedia.org/wiki/Association_for_Social_Advancement">ASA</a>. The main microfinance recommendation in the book is probably that loans shouldn't be only for micro-entrepreneurial purposes: people have a range of needs that loans can help with.</p>
<p><em>Portfolios</em> was talking about <a href="https://en.wikipedia.org/wiki/Behavioral_economics">behavioral economics</a> before it was cool. It was interesting hearing about rural microfinance administered through weekly group meetings, sometimes with the risks of group liability. They also describe some people's preferences for borrowing on interest rather than spending from savings because of the attendant motivation to pay back quickly, and ideas for commitment savings devices.</p>
<p>There were a lot of things I wasn't familiar with, and the authors provide a helpful glossary in a table footnote on pages 207-208.</p>
<ul>
<li><em>Chit funds</em> are a government regulated form of RoSCA (see below) found only in India.</li>
<li><em>Pro-poor insurers</em> are found only in Bangladesh: they adapt the methods of NGO microcredit banks to offer endowments (savings plans linked to life insurance) to the poor, and to recycle the premiums as loans to the poor.</li>
<li><em>Saving-up clubs</em> are clubs where participants save together toward a particular event, such as a religious festival: they do not recycle the fund as loans.</li>
<li><em>RoSCAs</em>, or rotating savings and credit associations, are a form of savings-and-loan club in which a fixed number of members pay a fixed sum into a pool at a fixed interval, and on each occasion one of the members takes the whole of the pool (there are many variants on this theme).</li>
<li><em>ASCAs</em>, or accumulating savings and credit associations differ from RoSCAs in that regularly depositing members accumulate their fund and lend it out when required to one or more of their members.</li>
<li><em>Burial societies</em>, as found in South Africa, are informal clubs where members insure each other against funeral costs.</li>
<li><em>Stokvels</em> and <em>umgalelos</em> are different names for South African RoSCAs and ASCAs.</li>
<li><em>Salary timing</em> is an agreement with others to share salaries as they arrive.</li>
<li><em>Reciprocal interest-free lending and borrowing</em> are loans between friends, neighbors or family members that are interest-free but bear the implied obligation to reciprocate at some time in the future.</li>
<li><em>Mahajan</em> and <em>mashonisa</em> are South Asian and South African terms for local money-lenders who lend for profit.</li>
<li><em>Moneyguarding</em> is having someone look after your money for you, often a relative, neighbor, employer or shopkeeper.</li>
<li><em>Remitting cash to the village</em> is often practiced by town dwellers as a way of saving and of building up assets in the home village. Note that in the South African study, we treated remitting cash to the village as an expense rather than a financial instrument because we knew that the households receiving the remittances were using it for their own needs rather than saving it. In Bangladesh and India, it was more often (but not always) the case that the money was invested in some way: in land or housing or lent out, for example, and we have treated remittances as savings.</li>
</ul>
<p>One of the interesting RoSCA variants is the auction RoSCA, whereby members effectively achieve different interest rates depending on how quickly they want it to be their turn for the lump payment.</p>
<p>There were also terms that aren't so obscure but were still not familiar to me.</p>
<ul>
<li><a href="https://www.investopedia.com/terms/c/credit_life_insurance.asp">Credit Life Insurance</a><ul>
<li>Pays off your debt if you die.</li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/Endowment_policy">Life-Endowment Savings</a><ul>
<li>Pays a lump sum after a term, or if you die.</li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/Debenture">Debenture</a><ul>
<li>Basically a bond; maybe (even) less asset-secured.</li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/Net_present_value">Net Present Value</a> (NPV)<ul>
<li>For a fixed period, positive if we beat a fixed compounding interest rate, negative if not: "Am I better off over the next three years buying this investment, or putting that money in the bank at 1.5% interest? (And by how much?)"</li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/Internal_rate_of_return">Internal Rate of Return</a> (IRR)<ul>
<li>Compounding interest rate equivalent of an investment: "If this factory were a bank account, what would it's APR be?"</li>
</ul>
</li>
</ul>
<p>It's pretty far from the purpose of the book, but I did appreciate the excuse to finally understand IRR a little better, along with everything else.</p>
<!-- The book has only a few typographic problems. For example, incorrect parentheses break the equation in the sixth endnote to chapter five, on page 257. -->

<blockquote>
<p>"In human affairs, incremental improvements can provide the basis for broader changes." (page 64)</p>
</blockquote>
<p><em>Thanks to the <a href="https://www.dclibrary.org/">DC Public Library</a> for supporting my access to this book.</em></p>    
    ]]></description>
<link>http://planspace.org/20180429-portfolios_of_the_poor/</link>
<guid>http://planspace.org/20180429-portfolios_of_the_poor/</guid>
<pubDate>Sun, 29 Apr 2018 12:00:00 -0500</pubDate>
</item>
<item>
<title>Consider Phlebas by Iain M. Banks</title>
<description><![CDATA[

<p>Amazon <a href="http://variety.com/2018/tv/news/consider-phlebas-iain-m-banks-amazon-novel-dennis-kelly-1202706327/">is</a> making a sci-fi TV show based on the 1987 <a href="https://en.wikipedia.org/wiki/Consider_Phlebas">Consider Phlebas</a>. Focusing on certain cultural aspects would be interesting, or it could be just another space opera.</p>
<p>There's a war between <a href="https://en.wikipedia.org/wiki/The_Culture">The Culture</a> and the <a href="https://en.wikipedia.org/wiki/List_of_civilisations_in_the_Culture_series#Idirans">Idirans</a>. They could stand in for modern American society: The Culture is liberal, the Idirans are conservative. In one paragraph Banks uses the word "contempt" eight times, which reminded me of <a href="https://www.amazon.com/Politics-Resentment-Consciousness-Wisconsin-American/dp/022634911X">The Politics of Resentment</a>. The comparison isn't perfect, but it could be explored.</p>
<p>Unfortunately, the bulk of the 514 pages is given to the details of who punched who, and how. Some ideas infiltrate a chapter about a cannibalistic cult, or poker for human lives. The chapters, especially early ones, are very episodic, and I could imagine Amazon following the material closely if they wanted to.</p>
<p>The Culture has sentient artificial Minds that participate in and even guide their society. This is the kind of thing I was hoping to read about, but it's largely swamped by swashbuckling. It would be neat to see Amazon produce a slightly more conceptual adventure based on the source material.</p>
<p>Why the weird title? It's from <a href="https://en.wikipedia.org/wiki/T._S._Eliot">T. S. Eliot</a>'s poem, <a href="https://en.wikipedia.org/wiki/The_Waste_Land">The Waste Land</a>. The relevant section:</p>
<hr>
<pre>
IV. Death by Water

Phlebas the Phoenician, a fortnight dead,
Forgot the cry of gulls, and the deep sea swell
And the profit and loss.
                                   A current under sea
Picked his bones in whispers. As he rose and fell
He passed the stages of his age and youth
Entering the whirlpool.
                                  Gentile or Jew
O you who turn the wheel and look to windward,
Consider Phlebas, who was once handsome and tall as you.
</pre>

<hr>
<p><a href="https://www.poetryfoundation.org/poems/47311/the-waste-land">The Waste Land</a> overflows with allusion; just to read the words as written requires six languages or so. <a href="https://en.wikipedia.org/wiki/Consider_Phlebas">Consider Phlebas</a>, in comparison, is much less dense.</p>
<p><img alt="Consider Phlebas cover" src="consider_phlebas.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20180312-consider_phlebas_by_iain_m_banks/</link>
<guid>http://planspace.org/20180312-consider_phlebas_by_iain_m_banks/</guid>
<pubDate>Mon, 12 Mar 2018 12:00:00 -0500</pubDate>
</item>
  </channel>
</rss>
