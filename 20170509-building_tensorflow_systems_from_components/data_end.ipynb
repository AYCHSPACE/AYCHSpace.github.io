{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting data in... to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_d = tf.constant(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(zero_d - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'sub/y' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(9, dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(zero_d, feed_dict={zero_d: 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'sub/y' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: This example gleefully uses `tf.constant()` and not `tf.placeholder()`. Really if you plan to feed data in, you should use `tf.placeholder()`. Also you likely want to provide more useful `name` values for things, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_d = tf.constant([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(one_d + [2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "two_d = tf.constant(np.array([[2, 2], [2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3],\n",
       "       [3, 3]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(two_d + [[1, 1], [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 9],\n",
       "       [9, 9]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(two_d, feed_dict={two_d: [[9, 9], [9, 9]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# getting data in... TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is how Caffe might store an image and label in LMDB.\n",
    "\n",
    "import caffe\n",
    "import lmdb\n",
    "\n",
    "image = np.ones((1, 28, 28))  # not a meaningful image\n",
    "label = 9  # for a classification problem\n",
    "\n",
    "datum = caffe.io.array_to_datum(arr=image, label=label)\n",
    "datum_str = datum.SerializeToString()\n",
    "\n",
    "env = lmdb.open('lmdb_data')\n",
    "txn = env.begin(write=True)\n",
    "txn.put(key='my datum', value=datum_str)\n",
    "\n",
    "cur = txn.cursor()\n",
    "same_datum_str = cur.get('my datum')\n",
    "\n",
    "same_datum = caffe.proto.caffe_pb2.Datum().FromString(same_datum_str)\n",
    "same_image = caffe.io.datum_to_array(same_datum)\n",
    "same_label = datum.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Caffe `datum` -> TensorFlow `Example`\n",
    " * LMDB database -> TensorFlow `TFRecords` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python dict:\n",
    "my_dict = {'features' : {\n",
    "    'my_ints': [5, 6],\n",
    "    'my_float': [2.7],\n",
    "    'my_bytes': ['data']\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TFRecords `Example`:\n",
    "my_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "    'my_ints': tf.train.Feature(int64_list=tf.train.Int64List(value=[5, 6])),\n",
    "    'my_float': tf.train.Feature(float_list=tf.train.FloatList(value=[2.7])),\n",
    "    'my_bytes': tf.train.Feature(bytes_list=tf.train.BytesList(value=['data']))\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = np.ones((1, 28, 28), dtype=np.uint8)  # not a meaningful image\n",
    "label = 9  # for a classification problem\n",
    "\n",
    "image_bytes = image.tostring()\n",
    "image_shape = image.shape\n",
    "\n",
    "my_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "    'image_bytes': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes])),\n",
    "    'image_shape': tf.train.Feature(int64_list=tf.train.Int64List(value=image_shape)),\n",
    "    'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_example_str = my_example.SerializeToString()\n",
    "with tf.python_io.TFRecordWriter('my_example.tfrecords') as writer:\n",
    "    writer.write(my_example_str)\n",
    "\n",
    "reader = tf.python_io.tf_record_iterator('my_example.tfrecords')\n",
    "those_examples = [tf.train.Example().FromString(example_str)\n",
    "                  for example_str in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "same_example = those_examples[0]\n",
    "same_image_bytes = same_example.features.feature['image_bytes'].bytes_list.value[0]\n",
    "same_image_shape = list(same_example.features.feature['image_shape'].int64_list.value)\n",
    "same_label = same_example.features.feature['label'].int64_list.value[0]\n",
    "same_image = np.fromstring(same_image_bytes, dtype=np.uint8)\n",
    "same_image.shape = same_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9L"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exploring\n",
    "\n",
    " * [Python quick reference](http://www.dataschool.io/python-quick-reference/)\n",
    " * `dir()` and `help()`\n",
    " * Using TensorFlow documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AggregationMethod',\n",
       " 'Assert',\n",
       " 'AttrValue',\n",
       " 'COMPILER_VERSION',\n",
       " 'ConditionalAccumulator',\n",
       " 'ConditionalAccumulatorBase',\n",
       " 'ConfigProto',\n",
       " 'DType',\n",
       " 'DeviceSpec',\n",
       " 'Dimension',\n",
       " 'Event',\n",
       " 'FIFOQueue',\n",
       " 'FixedLenFeature',\n",
       " 'FixedLenSequenceFeature',\n",
       " 'FixedLengthRecordReader',\n",
       " 'GIT_VERSION',\n",
       " 'GPUOptions',\n",
       " 'GRAPH_DEF_VERSION',\n",
       " 'GRAPH_DEF_VERSION_MIN_CONSUMER',\n",
       " 'GRAPH_DEF_VERSION_MIN_PRODUCER',\n",
       " 'Graph',\n",
       " 'GraphDef',\n",
       " 'GraphKeys',\n",
       " 'GraphOptions',\n",
       " 'HistogramProto',\n",
       " 'IdentityReader',\n",
       " 'IndexedSlices',\n",
       " 'InteractiveSession',\n",
       " 'LogMessage',\n",
       " 'NameAttrList',\n",
       " 'NoGradient',\n",
       " 'NodeDef',\n",
       " 'NotDifferentiable',\n",
       " 'OpError',\n",
       " 'Operation',\n",
       " 'OptimizerOptions',\n",
       " 'PaddingFIFOQueue',\n",
       " 'Print',\n",
       " 'PriorityQueue',\n",
       " 'QUANTIZED_DTYPES',\n",
       " 'QueueBase',\n",
       " 'RandomShuffleQueue',\n",
       " 'ReaderBase',\n",
       " 'RegisterGradient',\n",
       " 'RunMetadata',\n",
       " 'RunOptions',\n",
       " 'Session',\n",
       " 'SessionLog',\n",
       " 'SparseConditionalAccumulator',\n",
       " 'SparseFeature',\n",
       " 'SparseTensor',\n",
       " 'SparseTensorValue',\n",
       " 'Summary',\n",
       " 'TFRecordReader',\n",
       " 'Tensor',\n",
       " 'TensorArray',\n",
       " 'TensorInfo',\n",
       " 'TensorShape',\n",
       " 'TextLineReader',\n",
       " 'VERSION',\n",
       " 'VarLenFeature',\n",
       " 'Variable',\n",
       " 'VariableScope',\n",
       " 'WholeFileReader',\n",
       " '_LazyContribLoader',\n",
       " '__builtins__',\n",
       " '__compiler_version__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__git_version__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__version__',\n",
       " 'abs',\n",
       " 'accumulate_n',\n",
       " 'acos',\n",
       " 'add',\n",
       " 'add_check_numerics_ops',\n",
       " 'add_n',\n",
       " 'add_to_collection',\n",
       " 'all_variables',\n",
       " 'app',\n",
       " 'arg_max',\n",
       " 'arg_min',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'as_dtype',\n",
       " 'as_string',\n",
       " 'asin',\n",
       " 'assert_equal',\n",
       " 'assert_greater',\n",
       " 'assert_greater_equal',\n",
       " 'assert_integer',\n",
       " 'assert_less',\n",
       " 'assert_less_equal',\n",
       " 'assert_negative',\n",
       " 'assert_non_negative',\n",
       " 'assert_non_positive',\n",
       " 'assert_none_equal',\n",
       " 'assert_positive',\n",
       " 'assert_proper_iterable',\n",
       " 'assert_rank',\n",
       " 'assert_rank_at_least',\n",
       " 'assert_type',\n",
       " 'assert_variables_initialized',\n",
       " 'assign',\n",
       " 'assign_add',\n",
       " 'assign_sub',\n",
       " 'atan',\n",
       " 'batch_to_space',\n",
       " 'batch_to_space_nd',\n",
       " 'betainc',\n",
       " 'bfloat16',\n",
       " 'bincount',\n",
       " 'bitcast',\n",
       " 'bool',\n",
       " 'boolean_mask',\n",
       " 'broadcast_dynamic_shape',\n",
       " 'broadcast_static_shape',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'ceil',\n",
       " 'check_numerics',\n",
       " 'cholesky',\n",
       " 'cholesky_solve',\n",
       " 'clip_by_average_norm',\n",
       " 'clip_by_global_norm',\n",
       " 'clip_by_norm',\n",
       " 'clip_by_value',\n",
       " 'compat',\n",
       " 'complex',\n",
       " 'complex128',\n",
       " 'complex64',\n",
       " 'concat',\n",
       " 'cond',\n",
       " 'confusion_matrix',\n",
       " 'conj',\n",
       " 'constant',\n",
       " 'constant_initializer',\n",
       " 'container',\n",
       " 'contrib',\n",
       " 'control_dependencies',\n",
       " 'convert_to_tensor',\n",
       " 'convert_to_tensor_or_indexed_slices',\n",
       " 'convert_to_tensor_or_sparse_tensor',\n",
       " 'cos',\n",
       " 'count_nonzero',\n",
       " 'count_up_to',\n",
       " 'create_partitioned_variables',\n",
       " 'cross',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'decode_base64',\n",
       " 'decode_csv',\n",
       " 'decode_json_example',\n",
       " 'decode_raw',\n",
       " 'delete_session_tensor',\n",
       " 'depth_to_space',\n",
       " 'dequantize',\n",
       " 'deserialize_many_sparse',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_part',\n",
       " 'digamma',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'double',\n",
       " 'dynamic_partition',\n",
       " 'dynamic_stitch',\n",
       " 'edit_distance',\n",
       " 'einsum',\n",
       " 'encode_base64',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erfc',\n",
       " 'errors',\n",
       " 'estimator',\n",
       " 'exp',\n",
       " 'expand_dims',\n",
       " 'expm1',\n",
       " 'extract_image_patches',\n",
       " 'eye',\n",
       " 'fake_quant_with_min_max_args',\n",
       " 'fake_quant_with_min_max_args_gradient',\n",
       " 'fake_quant_with_min_max_vars',\n",
       " 'fake_quant_with_min_max_vars_gradient',\n",
       " 'fake_quant_with_min_max_vars_per_channel',\n",
       " 'fake_quant_with_min_max_vars_per_channel_gradient',\n",
       " 'fft',\n",
       " 'fft2d',\n",
       " 'fft3d',\n",
       " 'fill',\n",
       " 'fixed_size_partitioner',\n",
       " 'flags',\n",
       " 'float16',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'floor',\n",
       " 'floor_div',\n",
       " 'floordiv',\n",
       " 'floormod',\n",
       " 'foldl',\n",
       " 'foldr',\n",
       " 'gather',\n",
       " 'gather_nd',\n",
       " 'get_collection',\n",
       " 'get_collection_ref',\n",
       " 'get_default_graph',\n",
       " 'get_default_session',\n",
       " 'get_local_variable',\n",
       " 'get_seed',\n",
       " 'get_session_handle',\n",
       " 'get_session_tensor',\n",
       " 'get_variable',\n",
       " 'get_variable_scope',\n",
       " 'gfile',\n",
       " 'global_norm',\n",
       " 'global_variables',\n",
       " 'global_variables_initializer',\n",
       " 'gradients',\n",
       " 'graph_util',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'group',\n",
       " 'half',\n",
       " 'hessians',\n",
       " 'histogram_fixed_width',\n",
       " 'identity',\n",
       " 'ifft',\n",
       " 'ifft2d',\n",
       " 'ifft3d',\n",
       " 'igamma',\n",
       " 'igammac',\n",
       " 'imag',\n",
       " 'image',\n",
       " 'import_graph_def',\n",
       " 'initialize_all_tables',\n",
       " 'initialize_all_variables',\n",
       " 'initialize_local_variables',\n",
       " 'initialize_variables',\n",
       " 'int16',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'int8',\n",
       " 'invert_permutation',\n",
       " 'is_finite',\n",
       " 'is_inf',\n",
       " 'is_nan',\n",
       " 'is_non_decreasing',\n",
       " 'is_numeric_tensor',\n",
       " 'is_strictly_increasing',\n",
       " 'is_variable_initialized',\n",
       " 'layers',\n",
       " 'lbeta',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'lgamma',\n",
       " 'lin_space',\n",
       " 'linspace',\n",
       " 'load_file_system_library',\n",
       " 'load_op_library',\n",
       " 'local_variables',\n",
       " 'local_variables_initializer',\n",
       " 'log',\n",
       " 'log1p',\n",
       " 'logging',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'logical_xor',\n",
       " 'losses',\n",
       " 'make_template',\n",
       " 'map_fn',\n",
       " 'matching_files',\n",
       " 'matmul',\n",
       " 'matrix_band_part',\n",
       " 'matrix_determinant',\n",
       " 'matrix_diag',\n",
       " 'matrix_diag_part',\n",
       " 'matrix_inverse',\n",
       " 'matrix_set_diag',\n",
       " 'matrix_solve',\n",
       " 'matrix_solve_ls',\n",
       " 'matrix_transpose',\n",
       " 'matrix_triangular_solve',\n",
       " 'maximum',\n",
       " 'meshgrid',\n",
       " 'metrics',\n",
       " 'min_max_variable_partitioner',\n",
       " 'minimum',\n",
       " 'mod',\n",
       " 'model_variables',\n",
       " 'moving_average_variables',\n",
       " 'multinomial',\n",
       " 'multiply',\n",
       " 'name_scope',\n",
       " 'negative',\n",
       " 'newaxis',\n",
       " 'nn',\n",
       " 'no_op',\n",
       " 'no_regularizer',\n",
       " 'norm',\n",
       " 'not_equal',\n",
       " 'one_hot',\n",
       " 'ones',\n",
       " 'ones_initializer',\n",
       " 'ones_like',\n",
       " 'op_scope',\n",
       " 'orthogonal_initializer',\n",
       " 'pad',\n",
       " 'parallel_stack',\n",
       " 'parse_example',\n",
       " 'parse_single_example',\n",
       " 'parse_single_sequence_example',\n",
       " 'parse_tensor',\n",
       " 'placeholder',\n",
       " 'placeholder_with_default',\n",
       " 'polygamma',\n",
       " 'pow',\n",
       " 'py_func',\n",
       " 'python_io',\n",
       " 'pywrap_tensorflow',\n",
       " 'qint16',\n",
       " 'qint32',\n",
       " 'qint8',\n",
       " 'qr',\n",
       " 'quantize_v2',\n",
       " 'quantized_concat',\n",
       " 'quint16',\n",
       " 'quint8',\n",
       " 'random_crop',\n",
       " 'random_gamma',\n",
       " 'random_normal',\n",
       " 'random_normal_initializer',\n",
       " 'random_poisson',\n",
       " 'random_shuffle',\n",
       " 'random_uniform',\n",
       " 'random_uniform_initializer',\n",
       " 'range',\n",
       " 'rank',\n",
       " 'read_file',\n",
       " 'real',\n",
       " 'realdiv',\n",
       " 'reciprocal',\n",
       " 'reduce_all',\n",
       " 'reduce_any',\n",
       " 'reduce_join',\n",
       " 'reduce_logsumexp',\n",
       " 'reduce_max',\n",
       " 'reduce_mean',\n",
       " 'reduce_min',\n",
       " 'reduce_prod',\n",
       " 'reduce_sum',\n",
       " 'register_tensor_conversion_function',\n",
       " 'report_uninitialized_variables',\n",
       " 'required_space_to_batch_paddings',\n",
       " 'reset_default_graph',\n",
       " 'reshape',\n",
       " 'resource',\n",
       " 'resource_loader',\n",
       " 'reverse',\n",
       " 'reverse_sequence',\n",
       " 'reverse_v2',\n",
       " 'rint',\n",
       " 'round',\n",
       " 'rsqrt',\n",
       " 'saturate_cast',\n",
       " 'saved_model',\n",
       " 'scalar_mul',\n",
       " 'scan',\n",
       " 'scatter_add',\n",
       " 'scatter_div',\n",
       " 'scatter_mul',\n",
       " 'scatter_nd',\n",
       " 'scatter_nd_add',\n",
       " 'scatter_nd_sub',\n",
       " 'scatter_nd_update',\n",
       " 'scatter_sub',\n",
       " 'scatter_update',\n",
       " 'sdca',\n",
       " 'segment_max',\n",
       " 'segment_mean',\n",
       " 'segment_min',\n",
       " 'segment_prod',\n",
       " 'segment_sum',\n",
       " 'self_adjoint_eig',\n",
       " 'self_adjoint_eigvals',\n",
       " 'sequence_mask',\n",
       " 'serialize_many_sparse',\n",
       " 'serialize_sparse',\n",
       " 'set_random_seed',\n",
       " 'setdiff1d',\n",
       " 'sets',\n",
       " 'shape',\n",
       " 'shape_n',\n",
       " 'sigmoid',\n",
       " 'sign',\n",
       " 'sin',\n",
       " 'size',\n",
       " 'slice',\n",
       " 'space_to_batch',\n",
       " 'space_to_batch_nd',\n",
       " 'space_to_depth',\n",
       " 'sparse_add',\n",
       " 'sparse_concat',\n",
       " 'sparse_fill_empty_rows',\n",
       " 'sparse_mask',\n",
       " 'sparse_matmul',\n",
       " 'sparse_maximum',\n",
       " 'sparse_merge',\n",
       " 'sparse_minimum',\n",
       " 'sparse_placeholder',\n",
       " 'sparse_reduce_sum',\n",
       " 'sparse_reduce_sum_sparse',\n",
       " 'sparse_reorder',\n",
       " 'sparse_reset_shape',\n",
       " 'sparse_reshape',\n",
       " 'sparse_retain',\n",
       " 'sparse_segment_mean',\n",
       " 'sparse_segment_sqrt_n',\n",
       " 'sparse_segment_sum',\n",
       " 'sparse_softmax',\n",
       " 'sparse_split',\n",
       " 'sparse_tensor_dense_matmul',\n",
       " 'sparse_tensor_to_dense',\n",
       " 'sparse_to_dense',\n",
       " 'sparse_to_indicator',\n",
       " 'sparse_transpose',\n",
       " 'spectral',\n",
       " 'split',\n",
       " 'sqrt',\n",
       " 'square',\n",
       " 'squared_difference',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'stop_gradient',\n",
       " 'strided_slice',\n",
       " 'string',\n",
       " 'string_join',\n",
       " 'string_split',\n",
       " 'string_to_hash_bucket',\n",
       " 'string_to_hash_bucket_fast',\n",
       " 'string_to_hash_bucket_strong',\n",
       " 'string_to_number',\n",
       " 'substr',\n",
       " 'subtract',\n",
       " 'summary',\n",
       " 'svd',\n",
       " 'sysconfig',\n",
       " 'tables_initializer',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'tensordot',\n",
       " 'test',\n",
       " 'tile',\n",
       " 'to_bfloat16',\n",
       " 'to_double',\n",
       " 'to_float',\n",
       " 'to_int32',\n",
       " 'to_int64',\n",
       " 'trace',\n",
       " 'train',\n",
       " 'trainable_variables',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncated_normal',\n",
       " 'truncated_normal_initializer',\n",
       " 'truncatediv',\n",
       " 'truncatemod',\n",
       " 'tuple',\n",
       " 'uint16',\n",
       " 'uint8',\n",
       " 'uniform_unit_scaling_initializer',\n",
       " 'unique',\n",
       " 'unique_with_counts',\n",
       " 'unsorted_segment_max',\n",
       " 'unsorted_segment_sum',\n",
       " 'unstack',\n",
       " 'user_ops',\n",
       " 'variable_axis_size_partitioner',\n",
       " 'variable_op_scope',\n",
       " 'variable_scope',\n",
       " 'variables_initializer',\n",
       " 'verify_tensor_all_finite',\n",
       " 'where',\n",
       " 'while_loop',\n",
       " 'write_file',\n",
       " 'zeros',\n",
       " 'zeros_initializer',\n",
       " 'zeros_like',\n",
       " 'zeta']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TFRecordReader in module tensorflow.python.ops.io_ops:\n",
      "\n",
      "class TFRecordReader(ReaderBase)\n",
      " |  A Reader that outputs the records from a TFRecords file.\n",
      " |  \n",
      " |  See ReaderBase for supported methods.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TFRecordReader\n",
      " |      ReaderBase\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, name=None, options=None)\n",
      " |      Create a TFRecordReader.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: A name for the operation (optional).\n",
      " |        options: A TFRecordOptions object (optional).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ReaderBase:\n",
      " |  \n",
      " |  num_records_produced(self, name=None)\n",
      " |      Returns the number of records this reader has produced.\n",
      " |      \n",
      " |      This is the same as the number of Read executions that have\n",
      " |      succeeded.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: A name for the operation (optional).\n",
      " |      \n",
      " |      Returns:\n",
      " |        An int64 Tensor.\n",
      " |  \n",
      " |  num_work_units_completed(self, name=None)\n",
      " |      Returns the number of work units this reader has finished processing.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: A name for the operation (optional).\n",
      " |      \n",
      " |      Returns:\n",
      " |        An int64 Tensor.\n",
      " |  \n",
      " |  read(self, queue, name=None)\n",
      " |      Returns the next record (key, value pair) produced by a reader.\n",
      " |      \n",
      " |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      " |      Reader needs to start reading from a new file since it has\n",
      " |      finished with the previous file).\n",
      " |      \n",
      " |      Args:\n",
      " |        queue: A Queue or a mutable string Tensor representing a handle\n",
      " |          to a Queue, with string work items.\n",
      " |        name: A name for the operation (optional).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple of Tensors (key, value).\n",
      " |        key: A string scalar Tensor.\n",
      " |        value: A string scalar Tensor.\n",
      " |  \n",
      " |  read_up_to(self, queue, num_records, name=None)\n",
      " |      Returns up to num_records (key, value pairs) produced by a reader.\n",
      " |      \n",
      " |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      " |      Reader needs to start reading from a new file since it has\n",
      " |      finished with the previous file).\n",
      " |      It may return less than num_records even before the last batch.\n",
      " |      \n",
      " |      Args:\n",
      " |        queue: A Queue or a mutable string Tensor representing a handle\n",
      " |          to a Queue, with string work items.\n",
      " |        num_records: Number of records to read.\n",
      " |        name: A name for the operation (optional).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple of Tensors (keys, values).\n",
      " |        keys: A 1-D string Tensor.\n",
      " |        values: A 1-D string Tensor.\n",
      " |  \n",
      " |  reset(self, name=None)\n",
      " |      Restore a reader to its initial clean state.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: A name for the operation (optional).\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created Operation.\n",
      " |  \n",
      " |  restore_state(self, state, name=None)\n",
      " |      Restore a reader to a previously saved state.\n",
      " |      \n",
      " |      Not all Readers support being restored, so this can produce an\n",
      " |      Unimplemented error.\n",
      " |      \n",
      " |      Args:\n",
      " |        state: A string Tensor.\n",
      " |          Result of a SerializeState of a Reader with matching type.\n",
      " |        name: A name for the operation (optional).\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created Operation.\n",
      " |  \n",
      " |  serialize_state(self, name=None)\n",
      " |      Produce a string tensor that encodes the state of a reader.\n",
      " |      \n",
      " |      Not all Readers support being serialized, so this can produce an\n",
      " |      Unimplemented error.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: A name for the operation (optional).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A string Tensor.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ReaderBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  reader_ref\n",
      " |      Op that implements the reader.\n",
      " |  \n",
      " |  supports_serialize\n",
      " |      Whether the Reader implementation can serialize its state.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.TFRecordReader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Search: https://www.tensorflow.org/s/results/?q=TFRecordReader\n",
    " * Docs: https://www.tensorflow.org/api_docs/python/tf/TFRecordReader\n",
    " * Source: https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/python/ops/io_ops.py#L413"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
