<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="/styles/csshake.min.css">
    <link rel="stylesheet" type="text/css" href="/styles/zenburn.css">
    <link rel="stylesheet" type="text/css" href="/styles/planspace.css">
    <title>TF-IDF is about what matters</title>
  </head>
  <body>
    <article>
<h1>TF-IDF is about what matters</h1>
<p class="date">Saturday May 23, 2015</p>
<p>Consider a collection (or “corpus”, or “set”) of four sentences (or “documents”, or “strings”) made up of words (or “terms”, or “tokens”):</p>
<ol>
<li>“a cat and dog sat”</li>
<li>“a dog and cat sat”</li>
<li>“a cat sat and sat”</li>
<li>“a cat killed a dog”</li>
</ol>
<p>One thing we can do is transform to a “bag of words” representation, which just means we’re keeping track of what words there are but not what order they’re in. We could use binary values to represent whether a word appears or not:</p>
<pre><code class="language-text">      a    cat    and    dog    sat   killed
1     1      1      1      1      1        0
2     1      1      1      1      1        0
3     1      1      1      0      1        0
4     1      1      0      1      0        1</code></pre>

<p>In this representation we've lost word order, but we've also lost <em>term frequency</em>: we can't tell that sentence three has twice as much sitting as sentence two. Let's use the counts:</p>
<pre><code class="language-text">      a    cat    and    dog    sat   killed
1     1      1      1      1      1        0
2     1      1      1      1      1        0
3     1      1      1      0      2        0
4     2      1      0      1      0        1</code></pre>

<p>Now we can see how many times each term appears in each document.</p>
<p>Is it good that “killed” is given the same score as “cat”? The word “killed” is much rarer, after all; it is more “special” to sentence four. Let’s count the number of sentences that have each word, and call this the <em>document frequency</em>:</p>
<pre><code class="language-text">      a    cat    and    dog    sat  killed
      4      4      3      3      3       1</code></pre>

<p>The document frequencies are high for words that are boring, so dividing by the document frequencies will give us low scores for boring words and high scores for interesting words:</p>
<pre><code class="language-text">      a    cat    and   dog     sat  killed
1  0.25   0.25   0.33   0.33   0.33       0
2  0.25   0.25   0.33   0.33   0.33       0
3  0.25   0.25   0.33      0   0.67       0
4  0.50   0.25      0   0.33      0    1.00</code></pre>

<p>These scores match the intuition that “killed” is the most important word in sentence four, and that sentence three is more about “sat” than any other sentence, and so on. In addition to making some intuitive sense, scores like these tend to work well in classification tasks and so on.</p>
<p>All we did was this:</p>
<p>\[ \frac{\text{number of times the word is in this document}}{\text{number of documents the word is in}} \]</p>
<p>Or, for short:</p>
<p>\[ \frac{\text{term frequency}}{\text{document frequency}} \]</p>
<p>Dividing by a thing is the same as multiplying by its inverse, \( \frac{1}{\text{a thing}} \), so we can call this transformation <em>term frequency inverse document frequency</em>.</p>
<p>This is not a very difficult idea. You may have invented it yourself at some point. But it gets so buried in terminology and secondary implementation details that people sometimes talk about it as if it were a deep and mysterious modeling technique. (It's not.)</p>
<p>Here's an <a href="http://www.cs.utexas.edu/~ml/papers/marlin-dissertation-06.pdf">example</a> of how the exposition can lose people. It starts nicely:</p>
<blockquote>
<p>“Tokens that occur frequently in a given string should have higher contribution to similarity than those that occur few times, as should those tokens that are rare among the set of strings under consideration.”</p>
</blockquote>
<p>Who could disagree? Then it jumps to this:</p>
<blockquote>
<p>“The Term Frequency-Inverse Document Frequency (TF-IDF) weighting scheme achieves this by associating a weight \( w_{v_i,s} = \frac{N(v_i,s)}{\text{max}_{v_j \in s} N(v_j,s)} \cdot \text{log} \frac{N}{N(v_i)} \) with every token \( v_i \) from string \( s \), where \( N(v_i, s) \) is the number of times \( v_i \) occurs in \( s \) (term frequency), \( N \) is the number of strings in the overall corpus under consideration, and \( N(v_i) \) is the number of strings in the corpus that include \( v_i \) (document frequency).”</p>
</blockquote>
<p>There's some notation there, and we've also thrown in two normalizations and a log. None of this is a particularly big deal, but it makes TF-IDF seem complicated. There are <a href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf">a lot of ways</a> you could do the particulars of TF-IDF but they all achieve essentially what we did above by just counting and dividing.</p><!-- mathjax for formulas -->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </article>
    <footer>
      <hr />
      <ul>
        <li id="back_link">
          <a href="/">Plan <span class="rotate180">➔</span> Space</a>
        </li>
        <li>
          <a id="edit_link" href="https://github.com/ajschumacher/ajschumacher.github.io">Edit</a> this page
        </li>
        <li>
          Find <a id="aaron_link" href="/aaron/">Aaron</a> on
          <ul>
            <li>
              <a href="https://twitter.com/planarrowspace">Twitter</a>
            </li>
            <li>
              <a href="https://www.linkedin.com/in/ajschumacher">LinkedIn</a>
            </li>
            <li>
              <a href="https://plus.google.com/112658546306232777448/">Google+</a>
            </li>
            <li>
              <a href="https://github.com/ajschumacher">GitHub</a>
            </li>
            <li>
              <a href="mailto:ajschumacher@gmail.com">email</a>
            </li>
          </ul>
        </li>
        <li>
          Comment below
        </li>
      </ul>
      <hr />
    </footer>

<!-- my weird stuff -->
<script src="/scripts/planspace.js"></script>

<!-- syntax highlighting -->
<script src="/scripts/highlight.pack.js"></script>
<script type="text/javascript">hljs.initHighlightingOnLoad();</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-44351009-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- Disqus comments -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname = 'planspace';
  (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

  </body>
</html>
